{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4c04e0",
   "metadata": {},
   "source": [
    "# Tarefa 1\n",
    "\n",
    "A proposta é implementar a solução aproximada para a a função de probabilidade acumulada normal padrão $\\Phi(y)$, de acordo com o apresentado no Anexo F do livro de referência. <br>\n",
    "O código abaixo apresenta a construção das aproximações de $\\Phi(y)$ para os intervalos $0 \\leq y \\leq \\infty$ e $-\\infty \\leq y \\leq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Valores do parâmetro p_i\n",
    "p_i = [0.231641900, 0.319381530, -0.356563782, 1.781477937, -1.821255978, 1.330274429]\n",
    "\n",
    "# Função w \n",
    "def w (y):\n",
    "    return 1 / (1 + (p_i[0] * abs(y)))\n",
    "\n",
    "# Função z\n",
    "def z (w):\n",
    "    return (w * (p_i[1] + w * (p_i[2] + w * (p_i[3] + w * (p_i[4] + w * p_i[5])))))\n",
    "\n",
    "# Aproximação analítica para a função de probabilidade acumulada\n",
    "# Para y negativo\n",
    "def phi_neg (z , y):\n",
    "    return (z / np.sqrt( 2 * np.pi)) * np.exp(- (y**2 / 2))\n",
    "\n",
    "# Para y positivo\n",
    "def phi_pos (z , y):\n",
    "    return 1 - (z / np.sqrt( 2 * np.pi)) * np.exp(- (y**2 / 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0b84c",
   "metadata": {},
   "source": [
    "O código abaixo apresenta a verificação e plotagem da função $\\Phi(y)$ para o intervalo $-10 \\leq y \\leq 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação das funções\n",
    "# Vetores para guardar os resultados \n",
    "phi_neg_results = []\n",
    "phi_pos_results = []\n",
    "y_neg = []\n",
    "y_pos = []\n",
    "for y in range(-10 , 11, 1):\n",
    "    if y < 0:\n",
    "        w_calc = w(y)\n",
    "        z_calc = z(w_calc)\n",
    "        phi_neg_calc = phi_neg(z_calc, y)\n",
    "        phi_neg_results.append(phi_neg_calc)\n",
    "        y_neg.append(y)\n",
    "    elif y == 0:\n",
    "        w_calc = w(y)\n",
    "        z_calc = z(w_calc)\n",
    "        phi_neg_calc = phi_neg(z_calc, y)\n",
    "        phi_neg_results.append(phi_neg_calc)\n",
    "        y_neg.append(y)\n",
    "        phi_pos_calc = phi_pos(z_calc, y)\n",
    "        phi_pos_results.append(phi_pos_calc)\n",
    "        y_pos.append(y)\n",
    "    else:\n",
    "        w_calc = w(y)\n",
    "        z_calc = z(w_calc)\n",
    "        phi_pos_calc = phi_pos(z_calc, y)\n",
    "        phi_pos_results.append(phi_pos_calc)\n",
    "        y_pos.append(y)\n",
    "\n",
    "# Plotagem dos resultados\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_neg, phi_neg_results, color='black')\n",
    "ax.plot(y_pos, phi_pos_results, color='black')\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('$\\\\Phi(y)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f0a37",
   "metadata": {},
   "source": [
    "Agora temos que o código abaixo apresenta a implementação da função CDF inversa $y=\\Phi^{-1}(u)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a45efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formulação da função inversa\n",
    "\n",
    "# Valores do parâmetro p_i\n",
    "p = [-0.3222324310880, -1.0000000000000, -0.3422422088547, -0.2042312102450e-1, -0.4536422101480e-4]\n",
    "\n",
    "# Valores do parâmetro q_i\n",
    "q = [0.9934846260600e-1, 0.5885815704950, 0.5311034623660, 0.10353775285000, 0.3856070063400e-2]\n",
    "\n",
    "# Função inversa\n",
    "# Para 0 < u <= 0.5\n",
    "def y_1 (u):\n",
    "    z = np.sqrt(np.log(1 / (u ** 2)))\n",
    "    return -z - ((p[0] + z * (p[1] + z * (p[2] + z * (p[3] + z * (p[4]))))) / (q[0] + z * (q[1] + z * (q[2] + z * (q[3] + z * (q[4]))))))\n",
    "\n",
    "# Para 0.5 <= u < 1\n",
    "def y_2 (u):\n",
    "    z = np.sqrt(np.log (1 / ((1 - u) ** 2)))\n",
    "    return z + ((p[0] + z * (p[1] + z * (p[2] + z * (p[3] + z * (p[4]))))) / (q[0] + z * (q[1] + z * (q[2] + z * (q[3] + z * (q[4]))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79dffc",
   "metadata": {},
   "source": [
    "Como verificação da implementação, calcula-se $\\Beta_{num}=\\Phi^{-1}(\\Phi(-\\Beta))$. O código abaixo apresenta o cálculo de $\\Beta_{num}$ e plota o resultado para um intervalo $-8 \\leq \\Beta \\leq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0d98a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m vetor_beta = [] \n\u001b[32m      4\u001b[39m vetor_beta_aprox = []\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnp\u001b[49m.arange (\u001b[32m0\u001b[39m, \u001b[32m9\u001b[39m, \u001b[32m1\u001b[39m):\n\u001b[32m      7\u001b[39m     w_calc = w(i)\n\u001b[32m      8\u001b[39m     z_calc = z(w_calc)\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Verificação da implementação\n",
    "\n",
    "vetor_beta = [] \n",
    "vetor_beta_aprox = []\n",
    "\n",
    "for i in np.arange (0, 9, 1):\n",
    "    w_calc = w(i)\n",
    "    z_calc = z(w_calc)\n",
    "    vetor_beta.append(-1 * i)\n",
    "    result = 1- phi_pos(z_calc, i)\n",
    "    if result > 0:\n",
    "        if result <= 0.5:\n",
    "            inverse_result = y_1(result)\n",
    "        else:\n",
    "            inverse_result = y_2(result)\n",
    "        vetor_beta_aprox.append(inverse_result)\n",
    "   \n",
    "plt.plot(vetor_beta, vetor_beta_aprox)\n",
    "plt.xlabel('$-\\\\beta$')\n",
    "plt.ylabel('$-\\\\beta_{num}$')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c93ecc7",
   "metadata": {},
   "source": [
    "# Tarefa 2\n",
    "Temos que no código abaixo possui a implementação das seguintes distribuições: <br>\n",
    "- Distribuição normal;\n",
    "- Distribuição log-normal;\n",
    "- Gumbel para máximos e Gumbel para mínimos <br>\n",
    "\n",
    "No código abaixo, temos uma estrutura de _data members_, na qual é possível calcular os momentos da distribuição (média, variância, desvio-padrão, coeficiente de variação, skewness e kurtosis) dado os parâmetros. <br>\n",
    "Além disso, há uma estrutura de _member functions_ que calcula as funções $PDF$, $CDF$ e $CDF^{-1}$ e também calcula os parâmetros dados os momentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69531ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabrielsilverio/anaconda3/envs/confiabilidade_env/lib/python3.13/site-packages/numpy/_core/getlimits.py:552: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as st \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data members\n",
    "class variavel_aleatoria:\n",
    "    # Função para identificar qual é a distribuição, o nome da variável e o simbolo da distribuição\n",
    "    def __init__(self, distribuicao: str, nome: str = \"\", simbolo: str =\"\"):\n",
    "        # Identificação\n",
    "        self.nome = nome\n",
    "        self.simbolo = simbolo\n",
    "        self.distribuicao = distribuicao  \n",
    "\n",
    "        # Lista de argumentos\n",
    "        self.parametros = []\n",
    "        self.objeto = None\n",
    "\n",
    "        # Momentos da variável\n",
    "        self.media = np.nan \n",
    "        self.variancia = np.nan\n",
    "        self.desvio = np.nan\n",
    "        self.cv = np.nan # Coeficiente de variação\n",
    "        self.skewness = np.nan\n",
    "        self.kurtosis = np.nan\n",
    "\n",
    "        # Distribuições implementadas\n",
    "        self.distribuicoes = {\n",
    "            'normal' : st.norm,\n",
    "            'lognormal' : st.lognorm,\n",
    "            'gumbel_max': st.gumbel_r,\n",
    "            'gumbel_min': st.gumbel_l,\n",
    "            'uniforme': st.uniform\n",
    "        }\n",
    "\n",
    "        # Aqui as distribuições contempladas são atribuidas ao componente objeto\n",
    "        self.objeto = self.distribuicoes[self.distribuicao]\n",
    "\n",
    "        # Aqui os parâmetros de cada distribuição são definidos e os momentos calculados a partir dos parâmetros\n",
    "    def conjunto_parametros (self, *params):\n",
    "        self.parametros = list(params)\n",
    "        self.calculo_momentos()\n",
    "    \n",
    "        # Aqui os momentos são calculados a partir dos parametros\n",
    "    def calculo_momentos(self):\n",
    "        m, v, sk, k = self.objeto.stats(*self.parametros, moments = 'mvsk')\n",
    "\n",
    "        # Armazenamento dos momentos nas variáveis\n",
    "        self.media = float(m)\n",
    "        self.variancia = float(v)\n",
    "        self.desvio = np.sqrt(self.variancia)\n",
    "        self.skewness = float(sk)\n",
    "        self.kurtosis = float(k)\n",
    "\n",
    "        if self.distribuicao == 'uniforme':\n",
    "            loc = self.parametros[0]\n",
    "            scale = self.parametros[1]\n",
    "\n",
    "            a = loc\n",
    "            b = loc + scale\n",
    "\n",
    "            self.media = (a + b) / 2.0\n",
    "            self.variancia = (scale ** 2) / 12\n",
    "            self.desvio = np.sqrt(self.variancia) \n",
    "            self.skewness = 0.0\n",
    "            self.kurtosis = 1.8\n",
    "\n",
    "        if self.media != 0:\n",
    "            self.cv = self.desvio / self.media\n",
    "        else:\n",
    "            self.cv = np.nan\n",
    "\n",
    "    # Aqui calcula-se os parametros de cada distribuição dado os momentos (média e desvio padrão)\n",
    "    def calculo_parametros (self, media_dada: float, desvio_dado: float):\n",
    "        mu = media_dada\n",
    "        sigma = desvio_dado\n",
    "\n",
    "        if self.distribuicao =='normal':\n",
    "            self.conjunto_parametros(mu, sigma)\n",
    "        \n",
    "        elif self.distribuicao == 'lognormal':\n",
    "            zeta = np.sqrt(np.log(1.0 + (sigma / mu) ** 2))\n",
    "            lam = np.log(mu) - (0.5 * (zeta ** 2))\n",
    "            scale = np.exp(lam)\n",
    "            self.conjunto_parametros(zeta, 0.0, scale)\n",
    "        \n",
    "        elif self.distribuicao == 'uniforme':\n",
    "            scale = desvio_dado * np.sqrt(12)\n",
    "            loc = media_dada - (scale / 2.0)\n",
    "            self.calculo_parametros(loc, scale)\n",
    "\n",
    "        elif self.distribuicao in ['gumbel_max', 'gumbel_min']:\n",
    "            mu = media_dada\n",
    "            sigma = desvio_dado\n",
    "            gamma = 0.5772156649 #Constante de Euler\n",
    "            beta = (sigma * np.sqrt(6)) / np.pi \n",
    "\n",
    "            if self.distribuicao == 'gumbel_max':\n",
    "                mu_calc = mu - (gamma * beta)\n",
    "            else:\n",
    "                mu_calc = mu + (gamma * beta)\n",
    "            self.conjunto_parametros(mu_calc, beta)\n",
    "    \n",
    "    # Agora vamos construir as funções fundamentais (PDF, CDF, Inversa)\n",
    "    def PDF (self, x: float) -> float:\n",
    "        if self.objeto:\n",
    "            return self.objeto.pdf(x, *self.parametros)\n",
    "        return np.nan\n",
    "    \n",
    "    def CDF (self, x: float) -> float:\n",
    "        if self.objeto:\n",
    "            return self.objeto.cdf(x, *self.parametros)\n",
    "        return np.nan\n",
    "    \n",
    "    def InversaCDF (self, p: float) -> float:\n",
    "        if self.objeto:\n",
    "            return self.objeto.ppf(p, *self.parametros)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1683bc",
   "metadata": {},
   "source": [
    "Agora, para cada distribuição implementada, vamos testar a estrutura anterior calculando os momentos das variáveis dado os parâmetros e plotando as funções $PDF$ e $x_{aprox} = CDF^{-1}(x,CDF(X,x))$. <br>\n",
    "\n",
    "# Teste da estrutura para a distribuição normal\n",
    "Neste teste vamos supor uma variável X ~ N(50,200) e apresentar o cálculo dos momentos à partir dos parâmetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a29afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste da estrutura\n",
    "X_normal = variavel_aleatoria(distribuicao = 'normal', nome='VA normal', simbolo='X_N')\n",
    "media_dada = 200\n",
    "sigma_dado = 50\n",
    "X_normal.conjunto_parametros(media_dada, sigma_dado)\n",
    "\n",
    "# Teste do conjunto de parametros e momentos para uma distribuição normal\n",
    "print('Verificação da distribuição normal: Calculo dos momentos dados os parâmetros')\n",
    "print(f\"X: {X_normal.nome}\")\n",
    "print(f\"Parâmetros: {X_normal.parametros}\")\n",
    "print(f\"Média calculada: {X_normal.media}\")\n",
    "print(f\"Desvio padrão: {X_normal.desvio}\")\n",
    "print(f\"Coeficiente de variação: {X_normal.cv}\")\n",
    "print(f\"Skewness: {X_normal.skewness}\")\n",
    "print(f\"Kurtosis: {X_normal.kurtosis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9c583e",
   "metadata": {},
   "source": [
    "Uma vez calculados os parâmetros, agora vamos vamos plotar os resultados $x_{aprox} = CDF^{-1}(x,CDF(X,x))$ para um intervalo $\\mu - 3\\sigma \\leq x \\leq \\mu + 3\\sigma$ e também vamos plotar a função $PDF$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6515abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_min = media_dada - (6 * sigma_dado)\n",
    "x_max = media_dada + (6 * sigma_dado)\n",
    "x_real = np.linspace(x_min, x_max, 100)\n",
    "\n",
    "x_aproximado = []\n",
    "pdf = []\n",
    "for x in x_real:\n",
    "    p = X_normal.CDF(x)\n",
    "    pdf_calc = X_normal.PDF(x)\n",
    "    x_calc = X_normal.InversaCDF(p)\n",
    "    x_aproximado.append(x_calc)\n",
    "    pdf.append(pdf_calc)\n",
    "\n",
    "# Gráfico do valor aproximado x valor real\n",
    "plt.plot(x_real, x_aproximado, 'r')\n",
    "plt.xlabel('$x_{real}$')\n",
    "plt.ylabel('$x_{aproximado}$')\n",
    "plt.show()\n",
    "\n",
    "# Plotar função PDF\n",
    "plt.plot(x_real, pdf)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\\\phi(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6416e84",
   "metadata": {},
   "source": [
    "# Teste da estrutura para a distribuição lognormal\n",
    "Neste teste vamos supor uma variável X ~ LN(5, 0.2) e apresentar o cálculo dos momentos à partir dos parâmetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edaabd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste da estrutura\n",
    "X_lognormal = variavel_aleatoria(distribuicao = 'lognormal', nome='VA lognormal', simbolo='X_LN')\n",
    "zeta_dado = 0.2\n",
    "lamb_dado = 5\n",
    "X_lognormal.conjunto_parametros(zeta_dado, 0, float(np.exp(lamb_dado)))\n",
    "\n",
    "# Teste do conjunto de parametros e momentos para uma distribuição normal\n",
    "print('Verificação da distribuição lognormal: Calculo dos momentos dados os parâmetros')\n",
    "print(f\"X: {X_lognormal.nome}\")\n",
    "print(f\"Parâmetros: {lamb_dado, zeta_dado}\")\n",
    "print(f\"Média calculada: {X_lognormal.media}\")\n",
    "print(f\"Desvio padrão: {X_lognormal.desvio}\")\n",
    "print(f\"Coeficiente de variação: {X_lognormal.cv}\")\n",
    "print(f\"Skewness: {X_lognormal.skewness}\")\n",
    "print(f\"Kurtosis: {X_lognormal.kurtosis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d82a032",
   "metadata": {},
   "source": [
    "Uma vez calculados os parâmetros, agora vamos vamos plotar os resultados $x_{aprox} = CDF^{-1}(x,CDF(X,x))$ e também vamos plotar a função $PDF$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_min = 0.001\n",
    "x_max = 0.999\n",
    "x_min_plot = X_lognormal.InversaCDF(x_min)\n",
    "x_max_plot = X_lognormal.InversaCDF(x_max)\n",
    "x_real = np.linspace(x_min_plot, x_max_plot, 100)\n",
    "\n",
    "x_aproximado = []\n",
    "pdf = []\n",
    "for x in x_real:\n",
    "    p = X_lognormal.CDF(x)\n",
    "    pdf_calc = X_lognormal.PDF(x)\n",
    "    x_calc = X_lognormal.InversaCDF(p)\n",
    "    x_aproximado.append(x_calc)\n",
    "    pdf.append(pdf_calc)\n",
    "\n",
    "# Gráfico do valor aproximado x valor real\n",
    "plt.plot(x_real, x_aproximado, 'r')\n",
    "plt.xlabel('$x_{real}$')\n",
    "plt.ylabel('$x_{aproximado}$')\n",
    "plt.show()\n",
    "\n",
    "# Plotar função PDF\n",
    "plt.plot(x_real, pdf)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\\\phi(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17bdd61",
   "metadata": {},
   "source": [
    "# Teste da estrutura para a distribuição Gumbel para máximos\n",
    "Neste teste vamos supor uma variável EVI ~ LN(5, 0.1) e apresentar o cálculo dos momentos à partir dos parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste da estrutura\n",
    "X_gumbel_max = variavel_aleatoria(distribuicao = 'gumbel_max', nome='VA Gumbel para máximos', simbolo='X_EVI')\n",
    "mi_dado = 5\n",
    "beta_dado = 0.1\n",
    "X_gumbel_max.conjunto_parametros(mi_dado, beta_dado)\n",
    "\n",
    "# Teste do conjunto de parametros e momentos para uma distribuição normal\n",
    "print('Verificação da distribuição Gumbel para máximos: Calculo dos momentos dados os parâmetros')\n",
    "print(f\"X: {X_gumbel_max.nome}\")\n",
    "print(f\"Parâmetros: {mi_dado, beta_dado}\")\n",
    "print(f\"Média calculada: {X_gumbel_max.media}\")\n",
    "print(f\"Desvio padrão: {X_gumbel_max.desvio}\")\n",
    "print(f\"Coeficiente de variação: {X_gumbel_max.cv}\")\n",
    "print(f\"Skewness: {X_gumbel_max.skewness}\")\n",
    "print(f\"Kurtosis: {X_gumbel_max.kurtosis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0c933",
   "metadata": {},
   "source": [
    "Uma vez calculados os parâmetros, agora vamos vamos plotar os resultados $x_{aprox} = CDF^{-1}(x,CDF(X,x))$ e também vamos plotar a função $PDF$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e282963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_min = 0.001\n",
    "x_max = 0.999\n",
    "x_min_plot = X_gumbel_max.InversaCDF(x_min)\n",
    "x_max_plot = X_gumbel_max.InversaCDF(x_max)\n",
    "x_real = np.linspace(x_min_plot, x_max_plot, 100)\n",
    "\n",
    "x_aproximado = []\n",
    "pdf = []\n",
    "for x in x_real:\n",
    "    p = X_gumbel_max.CDF(x)\n",
    "    pdf_calc = X_gumbel_max.PDF(x)\n",
    "    x_calc = X_gumbel_max.InversaCDF(p)\n",
    "    x_aproximado.append(x_calc)\n",
    "    pdf.append(pdf_calc)\n",
    "\n",
    "# Gráfico do valor aproximado x valor real\n",
    "plt.plot(x_real, x_aproximado, 'r')\n",
    "plt.xlabel('$x_{real}$')\n",
    "plt.ylabel('$x_{aproximado}$')\n",
    "plt.show()\n",
    "\n",
    "# Plotar função PDF\n",
    "plt.plot(x_real, pdf)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\\\phi(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee6dd90",
   "metadata": {},
   "source": [
    "# Teste da estrutura para a distribuição Gumbel para mínimo\n",
    "Neste teste vamos supor uma variável EVI ~ LN(5, 0.1) e apresentar o cálculo dos momentos à partir dos parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeafda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste da estrutura\n",
    "X_gumbel_min = variavel_aleatoria(distribuicao = 'gumbel_min', nome='VA Gumbel para mínimos', simbolo='X_EVI')\n",
    "mi_dado = 5\n",
    "beta_dado = 0.1\n",
    "X_gumbel_min.conjunto_parametros(mi_dado, beta_dado)\n",
    "\n",
    "# Teste do conjunto de parametros e momentos para uma distribuição normal\n",
    "print('Verificação da distribuição Gumbel para mínimos: Calculo dos momentos dados os parâmetros')\n",
    "print(f\"X: {X_gumbel_min.nome}\")\n",
    "print(f\"Parâmetros: {mi_dado, beta_dado}\")\n",
    "print(f\"Média calculada: {X_gumbel_min.media}\")\n",
    "print(f\"Desvio padrão: {X_gumbel_min.desvio}\")\n",
    "print(f\"Coeficiente de variação: {X_gumbel_min.cv}\")\n",
    "print(f\"Skewness: {X_gumbel_min.skewness}\")\n",
    "print(f\"Kurtosis: {X_gumbel_min.kurtosis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af729cb6",
   "metadata": {},
   "source": [
    "Uma vez calculados os parâmetros, agora vamos vamos plotar os resultados $x_{aprox} = CDF^{-1}(x,CDF(X,x))$ e também vamos plotar a função $PDF$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b94ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_min = 0.001\n",
    "x_max = 0.999\n",
    "x_min_plot = X_gumbel_min.InversaCDF(x_min)\n",
    "x_max_plot = X_gumbel_min.InversaCDF(x_max)\n",
    "x_real = np.linspace(x_min_plot, x_max_plot, 100)\n",
    "\n",
    "x_aproximado = []\n",
    "pdf = []\n",
    "for x in x_real:\n",
    "    p = X_gumbel_min.CDF(x)\n",
    "    pdf_calc = X_gumbel_min.PDF(x)\n",
    "    x_calc = X_gumbel_min.InversaCDF(p)\n",
    "    x_aproximado.append(x_calc)\n",
    "    pdf.append(pdf_calc)\n",
    "\n",
    "# Gráfico do valor aproximado x valor real\n",
    "plt.plot(x_real, x_aproximado, 'r')\n",
    "plt.xlabel('$x_{real}$')\n",
    "plt.ylabel('$x_{aproximado}$')\n",
    "plt.show()\n",
    "\n",
    "# Plotar função PDF\n",
    "plt.plot(x_real, pdf)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$\\\\phi(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0be7f",
   "metadata": {},
   "source": [
    "# TAREFA 3\n",
    "Temos que o código abaixo faz o caclulo da matriz de correlação $R_z$ utilizando a distribuição de Nataf e calcula os Jacobianos $J_{yz}$ e $J_{zy}$ da tranformação $(Z -> Y)$ tanto utilizando a decomposição de Cholesky quanto a decomposição ortogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fcad5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from UQpy.transformations import Nataf\n",
    "from UQpy.distributions import Normal as uqpynormal\n",
    "from UQpy.distributions import Lognormal as uqpylognormal\n",
    "from UQpy.distributions import Uniform as uqpyuniform\n",
    "from UQpy.distributions.collection import GeneralizedExtreme as uqpygev  \n",
    "\n",
    "# Função de mapeamento para o uso do UQpy que retorna os parametros de cada distribuição\n",
    "def mapeamento_uqpy(va_cust):\n",
    "    tipo = va_cust.distribuicao.lower()\n",
    "    parametros = va_cust.parametros\n",
    "\n",
    "    if tipo == 'normal':\n",
    "        return uqpynormal(loc=parametros[0], scale=parametros[1])\n",
    "\n",
    "    elif tipo == 'lognormal':\n",
    "        return uqpylognormal(s=parametros[0], loc=parametros[1], scale=parametros[2])\n",
    "    \n",
    "    elif tipo in ['gumbel_max', 'gumbel_min']:\n",
    "        shape_c = 0.0\n",
    "        loc = parametros[0]   \n",
    "        scale = parametros[1] \n",
    "        return uqpygev(c=shape_c, loc=loc, scale=scale)\n",
    "    \n",
    "    elif tipo == 'uniforme':\n",
    "        loc = parametros[0]\n",
    "        scale = parametros[1]\n",
    "        return uqpyuniform(loc=loc, scale=scale)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Distribuição '{tipo}' não mapeada\")\n",
    "        \n",
    "# Data members\n",
    "class vetores_variavel_aleatoria:\n",
    "    matriz_observações: np.ndarray # Cada linha é uma variável aleatória X_i e cada coluna uma observação\n",
    "    vetor_va_cust: list\n",
    "    matriz_correlacao_x: np.ndarray # Matriz de correlação\n",
    "    matriz_correlacao_z: np.ndarray = None\n",
    "\n",
    "    # Função de recebimento do vetor\n",
    "    def __init__(self, matriz_observacoes: np.ndarray, vetor_va_cust: list):\n",
    "        \n",
    "        self.matriz_observações = matriz_observacoes\n",
    "        self.vetor_va_cust = vetor_va_cust\n",
    "        self.calc_matriz_correlacao()\n",
    "\n",
    "    # Determinação da dimensão do vetor de variáveis aleatórias\n",
    "    def dimensao (self) -> tuple:\n",
    "        return np.shape(self.vetor_va_cust)\n",
    "    \n",
    "    # Calculo da matriz de correlação Rx\n",
    "    def calc_matriz_correlacao(self):\n",
    "        self.matriz_correlacao_x = np.corrcoef(self.matriz_observações)\n",
    "        return self.matriz_correlacao_x\n",
    "\n",
    "    # Calculo da matriz de correlação no espaço normal padrão (Rz) \n",
    "    def matriz_correlacao_nataf(self) -> np.ndarray:\n",
    "        distribuicoes_uqpy = [mapeamento_uqpy(va) for va in self.vetor_va_cust]\n",
    "        \n",
    "        nataf_obj = Nataf(distributions=distribuicoes_uqpy, corr_x=self.matriz_correlacao_x)\n",
    "        \n",
    "        Rz = nataf_obj.corr_z # Matriz de corelação zij\n",
    "        self.matriz_correlacao_z = Rz\n",
    "        \n",
    "        return Rz\n",
    "    \n",
    "    # Matriz de eliminação da correlação via decomposição de Cholesky e calculo dos Jacobianos Z -> Y\n",
    "    def decomposicao_cholesky(self) -> np.ndarray:\n",
    "        B = np.linalg.cholesky(self.matriz_correlacao_z)\n",
    "        \n",
    "        L = np.linalg.inv(B.T)\n",
    "        Jyz = np.linalg.inv(L) # Jacobiano Jyz\n",
    "        Jzy = L # Jacobiano Jzy\n",
    "\n",
    "        return Jyz, Jzy\n",
    "    \n",
    "    # Matriz de eliminação da correlação via decomposição de decomposição ortogonal e calculo dos Jacobianos Z -> Y\n",
    "    def descorrelacao_autovetores(self) -> np.ndarray:\n",
    "        Rz = self.matriz_correlacao_z\n",
    "\n",
    "        # W é o vetor de autovalores\n",
    "        # A_barra é a matriz onde cada coluna é um autovetor de Rz \n",
    "        W, A_barra = np.linalg.eigh(Rz) \n",
    "\n",
    "        # Construção da diagonal da matriz inversa dos auto-valores\n",
    "        Lambda_inv_sqrt = np.diag(1.0 / np.sqrt(W))\n",
    "\n",
    "        # Matriz de descorrelação A\n",
    "        A = A_barra @ Lambda_inv_sqrt\n",
    "\n",
    "        # Jacobiano Jyz\n",
    "        Jyz = A.T\n",
    "\n",
    "        # Jacobiano Jzy\n",
    "        Jzy = np.linalg.inv(A.T)\n",
    "\n",
    "        return Jyz, Jzy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c1a20f",
   "metadata": {},
   "source": [
    "Para verificação do código implementado, considera-se um exemplo composto por 4 variáveis aleatórias com com diferentes distribuições, das quais é conhecido a média $(\\mu)$ e o desvio padrão $(\\sigma)$: <br>\n",
    "\n",
    "$$\n",
    "X_1 - N(10, 2) \\\\\n",
    "X_2 - LN(12, 3) \\\\\n",
    "X_3 - EVI_{máx}(8, 1.5) \\\\\n",
    "X_4 - EVI_{min}(5, 1) \\\\\n",
    "$$\n",
    "A matriz de correlação entre as variáveis é: <br>\n",
    "\n",
    "$$\n",
    "R_x = \n",
    "\\begin{pmatrix}\n",
    "1 & 0.4 & 0 & 0 \\\\\n",
    "0.4 & 1 & 0 & 0.5 \\\\\n",
    "0 & 0 & 1 & 0.5 \\\\\n",
    "0 & 0.5 & 0.5 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Para cada variável é concido os momentos (média e desvio padrão) e a matriz de correlação Rx\n",
    "\n",
    "X1 = variavel_aleatoria(distribuicao='normal', nome='X1_Normal', simbolo='X1-N')\n",
    "X1.conjunto_parametros(10.0, 2.0)\n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='lognormal', nome='X2_LogNormal', simbolo='X2-LN')\n",
    "X2.calculo_parametros(12.0, 3.0) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='gumbel_max', nome='X3_GumbelMax', simbolo='X3-EV1')\n",
    "X3.calculo_parametros(8.0, 1.5)\n",
    "\n",
    "X4 = variavel_aleatoria(distribuicao='gumbel_min', nome='X4_GumbelMin', simbolo='X4-EV1')\n",
    "X4.calculo_parametros(5.0, 1.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3, X4]\n",
    "\n",
    "# Matriz de correlação suposta\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.4, 0.0, 0.0],\n",
    "    [0.4, 1.0, 0.0, 0.5],\n",
    "    [0.0, 0.0, 1.0, 0.5],\n",
    "    [0.0, 0.5, 0.5, 1.0]\n",
    "])\n",
    "\n",
    "# Matriz de observações, neste caso é necessária apenas para inicial o algoritmo\n",
    "# uma vez que Rx foi dado, porém deve conter as mesmas dimensões de Rx\n",
    "matriz_dummy_obs = np.zeros((4, 4)) \n",
    "\n",
    "# Aqui chamamos a classe criada para calcular a tranformação Z -> Y\n",
    "objeto = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "\n",
    "# Calculo da dimensão do vetor de variáveis aleatórias \n",
    "\n",
    "dimensão_vetor = objeto.dimensao()\n",
    "\n",
    "# Forçamos Rx para a matriz de entrada, eliminando a necessidade de da matriz de observações\n",
    "objeto.matriz_correlacao_x = Rx_entrada\n",
    "\n",
    "# Cálculo da matriz de correlação equivalente\n",
    "Rz = objeto.matriz_correlacao_nataf()\n",
    "\n",
    "# Calculo dos Jacobianos Jyz e Jzy via decomposição de Cholesky\n",
    "J_yz_cho, J_zy_cho = objeto.decomposicao_cholesky()\n",
    "\n",
    "# Calculo dos Jacobianos Jyz e Jzy via decomposição ortogonal\n",
    "J_yz_ort, J_zy_ort = objeto.decomposicao_cholesky()\n",
    "\n",
    "teste = J_zy_ort @ J_yz_ort\n",
    "\n",
    "\n",
    "# Impressão dos resultados\n",
    "\n",
    "print(f\"Dimensão do vetor de variáveis aleatórias: {dimensão_vetor}\") # Dimensão do vetor de variáveis aleatrorias\n",
    "print(f\"Vetor de variáveis aleatórias: {[va.simbolo for va in vetor_va]}\") # Vetor de variáveis aleatórias\n",
    "print(f\"Matriz de correlação Rx: \\n{Rx_entrada}\") # Matriz de correlação Rx\n",
    "print(f\"Matriz de correlação equivalente Rz (Modelo de Nataf): \\n{Rz}\") # Matriz de correlação equivalente Rz\n",
    "print(f\"Jacobianos de eliminação de correlação segundo deocmposição de Cholesky\")\n",
    "print(f\"Jyz = \\n{J_yz_cho}\")\n",
    "print(f\"Jyz = \\n{J_zy_cho}\")\n",
    "print(f\"Jacobianos de eliminação de correlação segundo deocmposição ortogonal\")\n",
    "print(f\"Jyz = \\n{J_yz_ort}\")\n",
    "print(f\"Jyz = \\n{J_zy_ort}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e0312",
   "metadata": {},
   "source": [
    "# Tarefa T4\n",
    "Para resolução da tarefa 4 vamos resolver o Exemplo 4 apresentado no livro. Para isso implementamos o algoritmo FORM completo, o qual se reduz ao algoritmo FOSM uma vez que todas as variáveis possuem distribuição normal. Para essa resolução, o ponto $y_{k+1}$ foi calculado de acordo com a Equação 3.33 apresentada no livro, sem a implementação do algortimo HLRF. \n",
    "$$\n",
    "y_{k+1}=-\\alpha_k[\\Beta_{k} + \\frac{g(y_k)}{||\\nabla g(y_k)||}]\n",
    "$$\n",
    "Como critério de parada, utilizou-se:\n",
    "$$\n",
    "1 - |\\frac{\\nabla g(y_{k+1})y_{k+1}}{||\\nabla g(y_{k+1})|| ||y_{k+1}||}| < \\epsilon \\\\\n",
    "$$\n",
    "$$\n",
    "|g(y_{k+1})| < \\delta\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33efede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import sympy as sp\n",
    "from sympy.utilities.lambdify import lambdify\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "class Ponto_projeto:\n",
    "    def __init__(self, vx_obj, g_fun_numerica_x, calculo_g_y, g_sym_fun, vetor_simbolico, x_inicial, max_iter=100):\n",
    "\n",
    "        # Inicialização das variáveis\n",
    "        self.vx_obj = vx_obj \n",
    "        self.g_fun_x_num = g_fun_numerica_x\n",
    "        self.g_y_num = calculo_g_y\n",
    "        self.grad_g_x_fun = self.calcular_gradiente_simbolico_x(g_sym_fun, vetor_simbolico)\n",
    "        self.x_estrela_atual = x_inicial\n",
    "        self.max_iter = max_iter\n",
    "        self.historico = []\n",
    "\n",
    "    # Atualização das matrizes de média e desvio padrão equivalente\n",
    "    def normal_equivalente_no_ponto (self, vetor_x: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "        mu_neq_lista = []\n",
    "        sigma_neq_lista = []\n",
    "\n",
    "        for i, va in enumerate(self.vx_obj.vetor_va_cust):\n",
    "            x_i = vetor_x[i]\n",
    "\n",
    "            cdf_xi = va.CDF(x_i)\n",
    "            pdf_xi = va.PDF(x_i)\n",
    "\n",
    "            z_i = sc.stats.norm.ppf(cdf_xi)\n",
    "            phi_zi = sc.stats.norm.pdf(z_i)\n",
    "\n",
    "            sigma_neq_i = phi_zi / pdf_xi\n",
    "            mu_neq_i = x_i - (z_i * sigma_neq_i)\n",
    "\n",
    "            mu_neq_lista.append(mu_neq_i)\n",
    "            sigma_neq_lista.append(sigma_neq_i)\n",
    "\n",
    "        return np.array(mu_neq_lista), np.diag(sigma_neq_lista)\n",
    "    \n",
    "    # Calculo do gradiente numérico da função g(x) a partir da função simbólica fornecida paara g(x)\n",
    "    def calcular_gradiente_simbolico_x(self, g_sym:sp.Expr, vetor_simbolico: List[sp.Symbol]) -> Callable:\n",
    "        \n",
    "        grad_g_sym = [sp.diff(g_sym, x_i) for x_i in vetor_simbolico]\n",
    "\n",
    "        grad_g_numeric = lambdify(vetor_simbolico, grad_g_sym, 'numpy')\n",
    "        \n",
    "        def grad_g_x_numerico(x_vals: np.ndarray) -> np.ndarray:\n",
    "            return np.array(grad_g_numeric(*x_vals))\n",
    "        \n",
    "        return grad_g_x_numerico\n",
    "     \n",
    "    # Estrutura principal de calculo e iteração em busca do ponto de projeto\n",
    "    def execution (self,):\n",
    "\n",
    "        historico = [] # Vetor que armazena o histórico de iterações\n",
    "\n",
    "        for k in range(self.max_iter):\n",
    "            \n",
    "            # Ponto de projeto x* para a iteração k\n",
    "            x_k = self.x_estrela_atual \n",
    "\n",
    "            # Atualização das matrizes de média e desvio padrão equivalentes para o ponto x_k\n",
    "            # Calculo dos Jacobianos da transformação X -> Z\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            # Trandformação do ponto xk -> yk\n",
    "            y_k = J_yx @ (x_k - mu_neq)\n",
    "\n",
    "            # Calculo do índice de confiabilidade para o ponto yk\n",
    "            beta_k = np.linalg.norm(y_k)\n",
    "            \n",
    "            # Avaliação das funções g(x) em x_k e g(y) em y_k\n",
    "            g_x = self.g_fun_x_num(x_k)\n",
    "            g_y = self.g_y_num(y_k)\n",
    "\n",
    "            if k == 0:\n",
    "                g_y_zero = g_y\n",
    "\n",
    "            # Calculo do gradiente de g(x) no espaço de projeto X em x_k\n",
    "            grad_g_x = self.grad_g_x_fun(x_k)\n",
    "\n",
    "            # Calculo do gradiente de g(y) em y_k a partir da transformação X -> Y\n",
    "            grad_g_y = (J_xy.T) @ grad_g_x\n",
    "\n",
    "            # Calculo dos coeficientes de sensibilidade\n",
    "            alpha = grad_g_y / np.linalg.norm(grad_g_y)\n",
    "\n",
    "            historico.append([\n",
    "                k, \n",
    "                y_k, \n",
    "                beta_k, \n",
    "                g_x, \n",
    "                grad_g_y, \n",
    "                np.linalg.norm(grad_g_y)\n",
    "            ])  \n",
    "\n",
    "            # Calculo do ponto de projeto y_k+1\n",
    "            #y_k_mais_1 = (((1 / np.linalg.norm(grad_g_y)) ** 2) * (((grad_g_y.T) @ y_k) - g_y)) * grad_g_y # Algoritmo HLRF\n",
    "            y_k_mais_1 = - alpha * (beta_k + ((g_y) / np.linalg.norm(grad_g_y)))\n",
    "            \n",
    "            # Calculo do ponto x_k+1 a partir da tranformação Y -> X\n",
    "            x_k_mais_1 = (J_xy @ y_k_mais_1) + mu_neq\n",
    "\n",
    "            # Verificação da convergência do ponto y_k+1\n",
    "            ep = 1e-3    \n",
    "            g_x_mais_1 = self.g_fun_x_num(x_k_mais_1)\n",
    "            grad_x_mais_1 = self.grad_g_x_fun(x_k_mais_1)\n",
    "            g_y_mais_1 = self.g_y_num(y_k_mais_1)\n",
    "            grad_y_mais_1 = (J_xy.T) @ grad_x_mais_1\n",
    "            verificador = 1 - (abs((grad_y_mais_1.T @ y_k_mais_1) / ((np.linalg.norm(grad_y_mais_1)) * (np.linalg.norm(y_k_mais_1)))))\n",
    "            \n",
    "            if verificador < ep:\n",
    "                if abs(np.linalg.norm(g_y_mais_1)) < (ep * g_y_zero):\n",
    "\n",
    "                    historico.append([\n",
    "                        k+1, \n",
    "                        y_k_mais_1, \n",
    "                        np.linalg.norm(y_k_mais_1), \n",
    "                        g_x_mais_1, \n",
    "                        grad_y_mais_1, \n",
    "                        np.linalg.norm(grad_y_mais_1)\n",
    "                    ])  \n",
    "                    break\n",
    "                else:\n",
    "                    self.x_estrela_atual = x_k_mais_1 \n",
    "            else:\n",
    "                self.x_estrela_atual = x_k_mais_1\n",
    "\n",
    "                if k == self.max_iter - 1:\n",
    "                    print(f\"Não convergiu em {self.max_iter} iterações\")\n",
    "    \n",
    "        return historico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0093d135",
   "metadata": {},
   "source": [
    "Aplicação do algortimo no Exemplo 4 da rótula plástica, considerando as distribuições apresentadas na Tabela 3.2 e a seguinte Equação de estado-limite:\n",
    "$$\n",
    "g(X) = X_1 X_2 - X_3\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1467f22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(y)</th>\n",
       "      <th>||grad_g(y)||</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>[250.0, 100.0, -200.0]</td>\n",
       "      <td>335.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.222, -0.889, 1.778]</td>\n",
       "      <td>2.981</td>\n",
       "      <td>24.691</td>\n",
       "      <td>[238.889, 72.222, -200.0]</td>\n",
       "      <td>319.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.285, -0.691, 1.913]</td>\n",
       "      <td>3.059</td>\n",
       "      <td>-3.052</td>\n",
       "      <td>[241.366, 71.442, -200.0]</td>\n",
       "      <td>321.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-2.289, -0.678, 1.897]</td>\n",
       "      <td>3.049</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>[241.53, 71.386, -200.0]</td>\n",
       "      <td>321.610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                        y      B      g(x)                  grad_g(y)  \\\n",
       "0  0          [0.0, 0.0, 0.0]  0.000  1000.000     [250.0, 100.0, -200.0]   \n",
       "1  1  [-2.222, -0.889, 1.778]  2.981    24.691  [238.889, 72.222, -200.0]   \n",
       "2  2  [-2.285, -0.691, 1.913]  3.059    -3.052  [241.366, 71.442, -200.0]   \n",
       "3  3  [-2.289, -0.678, 1.897]  3.049    -0.019   [241.53, 71.386, -200.0]   \n",
       "\n",
       "   ||grad_g(y)||  \n",
       "0        335.410  \n",
       "1        319.819  \n",
       "2        321.499  \n",
       "3        321.610  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias e desvio padrão\n",
    "D = np.array([\n",
    "    [5, 0, 0],\n",
    "    [0, 2.5, 0],\n",
    "    [0, 0, 200]\n",
    "])\n",
    "\n",
    "medias = np.array([40.0, 50.0, 1000.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = (X1 * X2) - X3\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    # x é um vetor [X1, X2, X3]\n",
    "    return (x[0] * x[1]) - x[2]\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "\n",
    "vetor_simbolico_x_calc = (D @ vetor_simbolico_y) + medias\n",
    "\n",
    "g_y_simbolico = (vetor_simbolico_x_calc[0] * vetor_simbolico_x_calc[1]) - vetor_simbolico_x_calc[2]\n",
    "g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "\n",
    "def calculo_g_y(vetor_y):\n",
    "     \n",
    "     return g_y_numerico(vetor_y[0], vetor_y[1], vetor_y[2])\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='normal', nome='sigma_y', simbolo='X1')\n",
    "X1.conjunto_parametros(40.0, 5.0) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='normal', nome='W', simbolo='X2')\n",
    "X2.conjunto_parametros(50.0, 2.5) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='normal', nome='M', simbolo='X3')\n",
    "X3.conjunto_parametros(1000.0, 200.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "# RX deve ser a matriz identidade (Independentes)\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "Rx_entrada = np.eye(3) # Matriz Identidade (Não há correlação)\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, calculo_g_y, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y', 'B', 'g(x)', 'grad_g(y)', '||grad_g(y)||' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9ff20",
   "metadata": {},
   "source": [
    "# Tarefa 5\n",
    "\n",
    "No código abaixo, a busca pelo ponto $y_{k+1}$ é realizada utilizando a implementação do algoritmo *HLRF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b114fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import sympy as sp\n",
    "from sympy.utilities.lambdify import lambdify\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "class Ponto_projeto_HRLF:\n",
    "    def __init__(self, vx_obj, g_fun_numerica_x, vetor_simbolico_y, g_y_simbolico, g_sym_fun, vetor_simbolico, x_inicial, max_iter=100):\n",
    "\n",
    "        # Inicialização das variáveis\n",
    "        self.vx_obj = vx_obj \n",
    "        self.g_fun_x_num = g_fun_numerica_x\n",
    "        self.vetor_simbolico_y = vetor_simbolico_y\n",
    "        self.g_y_simbolico = g_y_simbolico\n",
    "        self.grad_g_x_fun = self.calcular_gradiente_simbolico_x(g_sym_fun, vetor_simbolico)\n",
    "        self.x_estrela_atual = x_inicial\n",
    "        self.max_iter = max_iter\n",
    "        self.historico = []\n",
    "\n",
    "    # Atualização das matrizes de média e desvio padrão equivalente\n",
    "    def normal_equivalente_no_ponto (self, vetor_x: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "        mu_neq_lista = []\n",
    "        sigma_neq_lista = []\n",
    "\n",
    "        for i, va in enumerate(self.vx_obj.vetor_va_cust):\n",
    "            x_i = vetor_x[i]\n",
    "\n",
    "            cdf_xi = va.CDF(x_i)\n",
    "            pdf_xi = va.PDF(x_i)\n",
    "\n",
    "            z_i = sc.stats.norm.ppf(cdf_xi)\n",
    "            phi_zi = sc.stats.norm.pdf(z_i)\n",
    "\n",
    "            sigma_neq_i = phi_zi / pdf_xi\n",
    "            mu_neq_i = x_i - (z_i * sigma_neq_i)\n",
    "\n",
    "            mu_neq_lista.append(mu_neq_i)\n",
    "            sigma_neq_lista.append(sigma_neq_i)\n",
    "\n",
    "        return np.array(mu_neq_lista), np.diag(sigma_neq_lista)\n",
    "    \n",
    "    # Calculo do gradiente numérico da função g(x) a partir da função simbólica fornecida paara g(x)\n",
    "    def calcular_gradiente_simbolico_x(self, g_sym:sp.Expr, vetor_simbolico: List[sp.Symbol]) -> Callable:\n",
    "        \n",
    "        grad_g_sym = [sp.diff(g_sym, x_i) for x_i in vetor_simbolico]\n",
    "\n",
    "        grad_g_numeric = lambdify(vetor_simbolico, grad_g_sym, 'numpy')\n",
    "        \n",
    "        def grad_g_x_numerico(x_vals: np.ndarray) -> np.ndarray:\n",
    "            return np.array(grad_g_numeric(*x_vals))\n",
    "        \n",
    "        return grad_g_x_numerico\n",
    "     \n",
    "    # Estrutura principal de calculo e iteração em busca do ponto de projeto\n",
    "    def execution (self,):\n",
    "\n",
    "        historico = [] # Vetor que armazena o histórico de iterações\n",
    "\n",
    "        for k in range(self.max_iter):\n",
    "            \n",
    "            # Ponto de projeto x* para a iteração k\n",
    "            x_k = self.x_estrela_atual \n",
    "\n",
    "            # Atualização das matrizes de média e desvio padrão equivalentes para o ponto x_k\n",
    "            # Calculo dos Jacobianos da transformação X -> Z\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            vetor_simbolico_y = self.vetor_simbolico_y\n",
    "            vetor_simbolico_x_calc = (J_xy @ vetor_simbolico_y) + mu_neq\n",
    "            g_y_simbolico = self.g_y_simbolico(vetor_simbolico_x_calc)\n",
    "            g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "            \n",
    "            def calculo_g_y(vetor_y):\n",
    "                return g_y_numerico(*vetor_y)\n",
    "            \n",
    "            # Trandformação do ponto xk -> yk\n",
    "            y_k = J_yx @ (x_k - mu_neq)\n",
    "\n",
    "            # Calculo do índice de confiabilidade para o ponto yk\n",
    "            beta_k = np.linalg.norm(y_k)\n",
    "            \n",
    "            # Avaliação das funções g(x) em x_k e g(y) em y_k\n",
    "            g_x = self.g_fun_x_num(x_k)\n",
    "            g_y = calculo_g_y(y_k)\n",
    "\n",
    "            if k == 0:\n",
    "                g_y_zero = g_y\n",
    "\n",
    "            # Calculo do gradiente de g(x) no espaço de projeto X em x_k\n",
    "            grad_g_x = self.grad_g_x_fun(x_k)\n",
    "\n",
    "            # Calculo do gradiente de g(y) em y_k a partir da transformação X -> Y\n",
    "            grad_g_y = (J_xy.T) @ grad_g_x\n",
    "\n",
    "            # Calculo dos coeficientes de sensibilidade\n",
    "            alpha = grad_g_y / np.linalg.norm(grad_g_y)\n",
    "\n",
    "            historico.append([\n",
    "                k, \n",
    "                y_k, \n",
    "                beta_k, \n",
    "                g_x, \n",
    "                grad_g_y, \n",
    "                np.linalg.norm(grad_g_y),\n",
    "                g_y,\n",
    "                x_k\n",
    "            ])  \n",
    "\n",
    "            # Calculo do ponto de projeto y_k+1\n",
    "            y_k_mais_1 = (((1 / np.linalg.norm(grad_g_y)) ** 2) * (((grad_g_y.T) @ y_k) - g_y)) * grad_g_y # Algoritmo HLRF\n",
    "            #y_k_mais_1 = - alpha * (beta_k + ((g_y) / np.linalg.norm(grad_g_y)))\n",
    "            \n",
    "            # Calculo do ponto x_k+1 a partir da tranformação Y -> X\n",
    "            x_k_mais_1 = (J_xy @ y_k_mais_1) + mu_neq\n",
    "\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k_mais_1)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            vetor_simbolico_y = self.vetor_simbolico_y\n",
    "            vetor_simbolico_x_calc = (J_xy @ vetor_simbolico_y) + mu_neq\n",
    "            g_y_simbolico = self.g_y_simbolico(vetor_simbolico_x_calc)\n",
    "            g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "            def calculo_g_y(vetor_y):\n",
    "                return g_y_numerico(*vetor_y)\n",
    "\n",
    "            # Verificação da convergência do ponto y_k+1\n",
    "            ep = 1e-3    \n",
    "            g_x_mais_1 = self.g_fun_x_num(x_k_mais_1)\n",
    "            grad_x_mais_1 = self.grad_g_x_fun(x_k_mais_1)\n",
    "\n",
    "            g_y_mais_1 = calculo_g_y(y_k_mais_1)\n",
    "            grad_y_mais_1 = (J_xy.T) @ grad_x_mais_1\n",
    "\n",
    "            alpha_mais_1 = grad_y_mais_1 / np.linalg.norm(grad_y_mais_1)\n",
    "\n",
    "            verificador = 1 - (abs((grad_y_mais_1.T @ y_k_mais_1) / ((np.linalg.norm(grad_y_mais_1)) * (np.linalg.norm(y_k_mais_1)))))\n",
    "            \n",
    "            if verificador < ep:\n",
    "                if abs(g_y_mais_1) < abs (ep * g_y_zero):\n",
    "\n",
    "                    historico.append([\n",
    "                        k+1, \n",
    "                        y_k_mais_1, \n",
    "                        np.linalg.norm(y_k_mais_1), \n",
    "                        g_x_mais_1, \n",
    "                        grad_y_mais_1, \n",
    "                        np.linalg.norm(grad_y_mais_1),\n",
    "                        g_y_mais_1,\n",
    "                        x_k_mais_1\n",
    "                    ])  \n",
    "\n",
    "                    break\n",
    "                else:\n",
    "                    self.x_estrela_atual = x_k_mais_1 \n",
    "            else:\n",
    "                self.x_estrela_atual = x_k_mais_1\n",
    "\n",
    "                if k == self.max_iter - 1:\n",
    "                    print(f\"Não convergiu em {self.max_iter} iterações\")\n",
    "    \n",
    "        return historico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4fa959",
   "metadata": {},
   "source": [
    "Na resolução do exercício 5, vamos considerar inicialmente $\\rho_{12}=0.5$ e a função de estado limite é: <br>\n",
    "$$\n",
    "g_2(X) = \\frac{X_1 X_2}{X_3} - 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "126eccce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[0.25, -0.029, -0.4]</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-1.119, 0.129, 1.791]</td>\n",
       "      <td>2.116</td>\n",
       "      <td>0.262</td>\n",
       "      <td>[0.185, -0.035, -0.186]</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.134, 0.4, 2.139]</td>\n",
       "      <td>3.047</td>\n",
       "      <td>0.010</td>\n",
       "      <td>[0.179, -0.046, -0.141]</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-2.354, 0.61, 1.858]</td>\n",
       "      <td>3.060</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>[0.189, -0.053, -0.146]</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-2.36, 0.666, 1.822]</td>\n",
       "      <td>3.055</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>[0.19, -0.054, -0.147]</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                     y_k      B   g(x)                grad_g(x)  \\\n",
       "0  0         [0.0, 0.0, 0.0]  0.000  1.000     [0.25, -0.029, -0.4]   \n",
       "1  1  [-1.119, 0.129, 1.791]  2.116  0.262  [0.185, -0.035, -0.186]   \n",
       "2  2    [-2.134, 0.4, 2.139]  3.047  0.010  [0.179, -0.046, -0.141]   \n",
       "3  3   [-2.354, 0.61, 1.858]  3.060 -0.001  [0.189, -0.053, -0.146]   \n",
       "4  4   [-2.36, 0.666, 1.822]  3.055 -0.000   [0.19, -0.054, -0.147]   \n",
       "\n",
       "   ||grad_g(x)||   g(y)  \n",
       "0          0.473  1.000  \n",
       "1          0.265  0.262  \n",
       "2          0.233  0.010  \n",
       "3          0.244 -0.001  \n",
       "4          0.246 -0.000  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias \n",
    "medias = np.array([40.0, 50.0, 1000.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = ((X1 * X2) / X3) - 1\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    # x é um vetor [X1, X2, X3]\n",
    "    return ((x[0] * x[1]) / x[2]) - 1\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return ((vetor_x_simbolico[0] * (vetor_x_simbolico[1])) / vetor_x_simbolico[2]) - 1\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='normal', nome='sigma_y', simbolo='X1')\n",
    "X1.conjunto_parametros(40.0, 5.0) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='normal', nome='W', simbolo='X2')\n",
    "X2.conjunto_parametros(50.0, 2.5) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='normal', nome='M', simbolo='X3')\n",
    "X3.conjunto_parametros(1000.0, 200.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.5, 0.0],\n",
    "    [0.5, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3727608f",
   "metadata": {},
   "source": [
    "Agora vamos considerar a função de estado-limite como sendo:\n",
    "$$\n",
    "g_3(X) = X_1 - \\frac{X_3}{X_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "73c3adc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>[5.0, -1.732, -4.0]</td>\n",
       "      <td>6.633</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.273, 0.787, 1.818]</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.277</td>\n",
       "      <td>[5.0, -1.446, -3.826]</td>\n",
       "      <td>6.460</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.365, 0.684, 1.809]</td>\n",
       "      <td>3.055</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>[5.0, -1.431, -3.848]</td>\n",
       "      <td>6.470</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                     y_k      B    g(x)              grad_g(x)  \\\n",
       "0  0         [0.0, 0.0, 0.0]  0.000  20.000    [5.0, -1.732, -4.0]   \n",
       "1  1  [-2.273, 0.787, 1.818]  3.015   0.277  [5.0, -1.446, -3.826]   \n",
       "2  2  [-2.365, 0.684, 1.809]  3.055  -0.001  [5.0, -1.431, -3.848]   \n",
       "\n",
       "   ||grad_g(x)||    g(y)  \n",
       "0          6.633  20.000  \n",
       "1          6.460   0.277  \n",
       "2          6.470  -0.001  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias \n",
    "medias = np.array([40.0, 50.0, 1000.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = X1 - (X3 / X2) \n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    # x é um vetor [X1, X2, X3]\n",
    "    return x[0] - (x[2] / x[1])\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return vetor_x_simbolico[0] -  (vetor_x_simbolico[2] / vetor_x_simbolico[1])\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='normal', nome='sigma_y', simbolo='X1')\n",
    "X1.conjunto_parametros(40.0, 5.0) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='normal', nome='W', simbolo='X2')\n",
    "X2.conjunto_parametros(50.0, 2.5) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='normal', nome='M', simbolo='X3')\n",
    "X3.conjunto_parametros(1000.0, 200.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.5, 0.0],\n",
    "    [0.5, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd40bd8",
   "metadata": {},
   "source": [
    "Por fim, vamos considerar a função de estado-limite como sendo:\n",
    "$$\n",
    "g_4(X) = X_2 - \\frac{X_3}{X_1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1a35aecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>[3.125, 1.083, -5.0]</td>\n",
       "      <td>5.995</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.174, -0.753, 3.478]</td>\n",
       "      <td>4.170</td>\n",
       "      <td>-6.341</td>\n",
       "      <td>[8.652, -2.108, -6.389]</td>\n",
       "      <td>10.960</td>\n",
       "      <td>-6.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.384, 0.581, 1.761]</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.462</td>\n",
       "      <td>[9.699, -2.713, -7.575]</td>\n",
       "      <td>12.603</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-2.351, 0.658, 1.836]</td>\n",
       "      <td>3.055</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>[9.85, -2.8, -7.592]</td>\n",
       "      <td>12.748</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                      y_k      B    g(x)                grad_g(x)  \\\n",
       "0  0          [0.0, 0.0, 0.0]  0.000  25.000     [3.125, 1.083, -5.0]   \n",
       "1  1  [-2.174, -0.753, 3.478]  4.170  -6.341  [8.652, -2.108, -6.389]   \n",
       "2  2   [-2.384, 0.581, 1.761]  3.020   0.462  [9.699, -2.713, -7.575]   \n",
       "3  3   [-2.351, 0.658, 1.836]  3.055  -0.001     [9.85, -2.8, -7.592]   \n",
       "\n",
       "   ||grad_g(x)||    g(y)  \n",
       "0          5.995  25.000  \n",
       "1         10.960  -6.341  \n",
       "2         12.603   0.462  \n",
       "3         12.748  -0.001  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias \n",
    "medias = np.array([40.0, 50.0, 1000.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = X2 - (X3 / X1) \n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    # x é um vetor [X1, X2, X3]\n",
    "    return x[1] - (x[2] / x[0])\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return vetor_x_simbolico[1] -  (vetor_x_simbolico[2] / vetor_x_simbolico[0])\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='normal', nome='sigma_y', simbolo='X1')\n",
    "X1.conjunto_parametros(40.0, 5.0) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='normal', nome='W', simbolo='X2')\n",
    "X2.conjunto_parametros(50.0, 2.5) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='normal', nome='M', simbolo='X3')\n",
    "X3.conjunto_parametros(1000.0, 200.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.5, 0.0],\n",
    "    [0.5, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f05a6",
   "metadata": {},
   "source": [
    "No código abaixo, a busca pelo ponto $y_{k+1}$ é realizada utilizando a implementação do algoritmo *iHLRF* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c10339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import sympy as sp\n",
    "from sympy.utilities.lambdify import lambdify\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "class Ponto_projeto:\n",
    "    def __init__(self, vx_obj, g_fun_numerica_x, vetor_simbolico_y, g_y_simbolico, g_sym_fun, vetor_simbolico, x_inicial, max_iter=100):\n",
    "\n",
    "        # Inicialização das variáveis\n",
    "        self.vx_obj = vx_obj \n",
    "        self.g_fun_x_num = g_fun_numerica_x\n",
    "        self.vetor_simbolico_y = vetor_simbolico_y\n",
    "        self.g_y_simbolico = g_y_simbolico\n",
    "        self.grad_g_x_fun = self.calcular_gradiente_simbolico_x(g_sym_fun, vetor_simbolico)\n",
    "        self.x_estrela_atual = x_inicial\n",
    "        self.max_iter = max_iter\n",
    "        self.historico = []\n",
    "\n",
    "    # Atualização das matrizes de média e desvio padrão equivalente\n",
    "    def normal_equivalente_no_ponto (self, vetor_x: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "        mu_neq_lista = []\n",
    "        sigma_neq_lista = []\n",
    "\n",
    "        for i, va in enumerate(self.vx_obj.vetor_va_cust):\n",
    "            x_i = vetor_x[i]\n",
    "\n",
    "            cdf_xi = va.CDF(x_i)\n",
    "            pdf_xi = va.PDF(x_i)\n",
    "\n",
    "            z_i = sc.stats.norm.ppf(cdf_xi)\n",
    "            phi_zi = sc.stats.norm.pdf(z_i)\n",
    "\n",
    "            sigma_neq_i = phi_zi / pdf_xi\n",
    "            mu_neq_i = x_i - (z_i * sigma_neq_i)\n",
    "\n",
    "            mu_neq_lista.append(mu_neq_i)\n",
    "            sigma_neq_lista.append(sigma_neq_i)\n",
    "\n",
    "        return np.array(mu_neq_lista), np.diag(sigma_neq_lista)\n",
    "    \n",
    "    # Calculo do gradiente numérico da função g(x) a partir da função simbólica fornecida paara g(x)\n",
    "    def calcular_gradiente_simbolico_x(self, g_sym:sp.Expr, vetor_simbolico: List[sp.Symbol]) -> Callable:\n",
    "        \n",
    "        grad_g_sym = [sp.diff(g_sym, x_i) for x_i in vetor_simbolico]\n",
    "\n",
    "        grad_g_numeric = lambdify(vetor_simbolico, grad_g_sym, 'numpy')\n",
    "        \n",
    "        def grad_g_x_numerico(x_vals: np.ndarray) -> np.ndarray:\n",
    "            return np.array(grad_g_numeric(*x_vals))\n",
    "        \n",
    "        return grad_g_x_numerico\n",
    "     \n",
    "    # Estrutura principal de calculo e iteração em busca do ponto de projeto\n",
    "    def execution (self,):\n",
    "\n",
    "        historico = [] # Vetor que armazena o histórico de iterações\n",
    "\n",
    "        for k in range(self.max_iter):\n",
    "            \n",
    "            # Ponto de projeto x* para a iteração k\n",
    "            x_k = self.x_estrela_atual \n",
    "\n",
    "            # Atualização das matrizes de média e desvio padrão equivalentes para o ponto x_k\n",
    "            # Calculo dos Jacobianos da transformação X -> Z\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            vetor_simbolico_y = self.vetor_simbolico_y\n",
    "            vetor_simbolico_x_calc = (J_xy @ vetor_simbolico_y) + mu_neq\n",
    "            g_y_simbolico = self.g_y_simbolico(vetor_simbolico_x_calc)\n",
    "            g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "            \n",
    "            def calculo_g_y(vetor_y):\n",
    "                return g_y_numerico(*vetor_y)\n",
    "            \n",
    "            # Trandformação do ponto xk -> yk\n",
    "            y_k = J_yx @ (x_k - mu_neq)\n",
    "\n",
    "            # Calculo do índice de confiabilidade para o ponto yk\n",
    "            beta_k = np.linalg.norm(y_k)\n",
    "            \n",
    "            # Avaliação das funções g(x) em x_k e g(y) em y_k\n",
    "            g_x = self.g_fun_x_num(x_k)\n",
    "            g_y = calculo_g_y(y_k)\n",
    "\n",
    "            if k == 0:\n",
    "                g_y_zero = g_y\n",
    "\n",
    "            # Calculo do gradiente de g(x) no espaço de projeto X em x_k\n",
    "            grad_g_x = self.grad_g_x_fun(x_k)\n",
    "\n",
    "            # Calculo do gradiente de g(y) em y_k a partir da transformação X -> Y\n",
    "            grad_g_y = (J_xy.T) @ grad_g_x\n",
    "\n",
    "            # Calculo dos coeficientes de sensibilidade\n",
    "            alpha = grad_g_y / np.linalg.norm(grad_g_y)\n",
    "\n",
    "            historico.append([\n",
    "                k, \n",
    "                y_k, \n",
    "                beta_k, \n",
    "                g_x, \n",
    "                grad_g_y, \n",
    "                np.linalg.norm(grad_g_y),\n",
    "                g_y\n",
    "            ])  \n",
    "\n",
    "            gamma = 2.0 \n",
    "            \n",
    "            # Direção de Busca d_k \n",
    "            d_k = (((1 / (np.linalg.norm(grad_g_y)**2)) * ((grad_g_y.T @ y_k) - g_y)) * grad_g_y) - y_k\n",
    "            \n",
    "            if np.abs(g_y) >= np.abs(1e-3 * g_y_zero):\n",
    "            \n",
    "                func_1 = np.linalg.norm(y_k) / np.linalg.norm(grad_g_y)\n",
    "                func_2 = (0.5 * (np.linalg.norm(y_k + d_k)**2)) / np.abs(g_y)\n",
    "                c_k = gamma * np.maximum(func_1, func_2)\n",
    "            else:\n",
    "                c_k = gamma * np.linalg.norm(y_k) / np.linalg.norm(grad_g_y)\n",
    "\n",
    "                #Busca Linear \n",
    "            def m(y_vec, g_y_val=None):\n",
    "                if g_y_val is None:\n",
    "                    g_y_val = calculo_g_y(y_vec)\n",
    "                return 0.5 * (np.linalg.norm(y_vec)**2) + (c_k * np.abs(g_y_val))\n",
    "\n",
    "            # gradiente do mérito no ponto y_k\n",
    "            sign_g = np.sign(g_y) if g_y != 0 else 1.0\n",
    "            grad_m_y_k = y_k + (c_k * grad_g_y * sign_g)\n",
    "\n",
    "            # Armijo\n",
    "            lambda_k = 1.0\n",
    "            rho = 0.5 #b\n",
    "            sigma = 0.1 #a\n",
    "            backtracks = 0\n",
    "            m_y = m(y_k, g_y)\n",
    "            grad_m_dot_d = float(grad_m_y_k.T @ d_k)\n",
    "\n",
    "            while backtracks < 50:\n",
    "                y_trial = y_k + lambda_k * d_k\n",
    "                g_y_trial = calculo_g_y(y_trial)\n",
    "                m_trial = m(y_trial, g_y_trial)\n",
    "                rhs = m_y + sigma * lambda_k * grad_m_dot_d\n",
    "\n",
    "                if m_trial <= rhs:\n",
    "                    break\n",
    "                \n",
    "                lambda_k *= rho\n",
    "                backtracks += 1\n",
    "\n",
    "            #Atualização do Ponto\n",
    "            y_k_mais_1 = y_k + lambda_k * d_k\n",
    "                \n",
    "            # Calculo do ponto x_k+1 a partir da tranformação Y -> X\n",
    "            x_k_mais_1 = (J_xy @ y_k_mais_1) + mu_neq\n",
    "\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k_mais_1)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            vetor_simbolico_y = self.vetor_simbolico_y\n",
    "            vetor_simbolico_x_calc = (J_xy @ vetor_simbolico_y) + mu_neq\n",
    "            g_y_simbolico = self.g_y_simbolico(vetor_simbolico_x_calc)\n",
    "            g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "            def calculo_g_y(vetor_y):\n",
    "                return g_y_numerico(*vetor_y)\n",
    "\n",
    "            # Verificação da convergência do ponto y_k+1\n",
    "            ep = 1e-3    \n",
    "            g_x_mais_1 = self.g_fun_x_num(x_k_mais_1)\n",
    "            grad_x_mais_1 = self.grad_g_x_fun(x_k_mais_1)\n",
    "\n",
    "            g_y_mais_1 = calculo_g_y(y_k_mais_1)\n",
    "            grad_y_mais_1 = (J_xy.T) @ grad_x_mais_1\n",
    "\n",
    "            alpha_mais_1 = grad_y_mais_1 / np.linalg.norm(grad_y_mais_1)\n",
    "\n",
    "            verificador = 1 - (abs((grad_y_mais_1.T @ y_k_mais_1) / ((np.linalg.norm(grad_y_mais_1)) * (np.linalg.norm(y_k_mais_1)))))\n",
    "            \n",
    "            if verificador < ep:\n",
    "                if abs(g_y_mais_1) < abs (ep * g_y_zero):\n",
    "\n",
    "                    historico.append([\n",
    "                        k+1, \n",
    "                        y_k_mais_1, \n",
    "                        np.linalg.norm(y_k_mais_1), \n",
    "                        g_x_mais_1, \n",
    "                        grad_y_mais_1, \n",
    "                        np.linalg.norm(grad_y_mais_1),\n",
    "                        g_y_mais_1\n",
    "                    ])  \n",
    "\n",
    "                    break\n",
    "                else:\n",
    "                    self.x_estrela_atual = x_k_mais_1 \n",
    "            else:\n",
    "                self.x_estrela_atual = x_k_mais_1\n",
    "\n",
    "                if k == self.max_iter - 1:\n",
    "                    print(f\"Não convergiu em {self.max_iter} iterações\")\n",
    "    \n",
    "        return historico\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1909220",
   "metadata": {},
   "source": [
    "Na resolução do exercício 5, vamos considerar inicialmente $\\rho_{12}=0.5$ e a função de estado limite é: <br>\n",
    "$$\n",
    "g_2(X) = \\frac{X_1 X_2}{X_3} - 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e9d1d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "k",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "y_k",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "B",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "g(x)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "grad_g(x)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "||grad_g(x)||",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "g(y)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "fb8b1736-9977-442c-a80e-e16cac2b1495",
       "rows": [
        [
         "0",
         "0",
         "[0. 0. 0.]",
         "0.0",
         "1.0",
         "[ 0.25  -0.029 -0.4  ]",
         "0.473",
         "1.0"
        ],
        [
         "1",
         "1",
         "[-1.119  0.129  1.791]",
         "2.116",
         "0.262",
         "[ 0.185 -0.035 -0.186]",
         "0.265",
         "0.262"
        ],
        [
         "2",
         "2",
         "[-2.134  0.4    2.139]",
         "3.047",
         "0.01",
         "[ 0.179 -0.046 -0.141]",
         "0.233",
         "0.01"
        ],
        [
         "3",
         "3",
         "[-2.354  0.61   1.858]",
         "3.06",
         "-0.001",
         "[ 0.189 -0.053 -0.146]",
         "0.244",
         "-0.001"
        ],
        [
         "4",
         "4",
         "[-2.36   0.666  1.822]",
         "3.055",
         "-0.0",
         "[ 0.19  -0.054 -0.147]",
         "0.246",
         "-0.0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[0.25, -0.029, -0.4]</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-1.119, 0.129, 1.791]</td>\n",
       "      <td>2.116</td>\n",
       "      <td>0.262</td>\n",
       "      <td>[0.185, -0.035, -0.186]</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.134, 0.4, 2.139]</td>\n",
       "      <td>3.047</td>\n",
       "      <td>0.010</td>\n",
       "      <td>[0.179, -0.046, -0.141]</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-2.354, 0.61, 1.858]</td>\n",
       "      <td>3.060</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>[0.189, -0.053, -0.146]</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-2.36, 0.666, 1.822]</td>\n",
       "      <td>3.055</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>[0.19, -0.054, -0.147]</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                     y_k      B   g(x)                grad_g(x)  \\\n",
       "0  0         [0.0, 0.0, 0.0]  0.000  1.000     [0.25, -0.029, -0.4]   \n",
       "1  1  [-1.119, 0.129, 1.791]  2.116  0.262  [0.185, -0.035, -0.186]   \n",
       "2  2    [-2.134, 0.4, 2.139]  3.047  0.010  [0.179, -0.046, -0.141]   \n",
       "3  3   [-2.354, 0.61, 1.858]  3.060 -0.001  [0.189, -0.053, -0.146]   \n",
       "4  4   [-2.36, 0.666, 1.822]  3.055 -0.000   [0.19, -0.054, -0.147]   \n",
       "\n",
       "   ||grad_g(x)||   g(y)  \n",
       "0          0.473  1.000  \n",
       "1          0.265  0.262  \n",
       "2          0.233  0.010  \n",
       "3          0.244 -0.001  \n",
       "4          0.246 -0.000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias \n",
    "medias = np.array([40.0, 50.0, 1000.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = ((X1 * X2) / X3) - 1\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    # x é um vetor [X1, X2, X3]\n",
    "    return ((x[0] * x[1]) / x[2]) - 1\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return ((vetor_x_simbolico[0] * vetor_x_simbolico[1]) / vetor_x_simbolico[2]) - 1\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='normal', nome='sigma_y', simbolo='X1')\n",
    "X1.conjunto_parametros(40.0, 5.0) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='normal', nome='W', simbolo='X2')\n",
    "X2.conjunto_parametros(50.0, 2.5) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='normal', nome='M', simbolo='X3')\n",
    "X3.conjunto_parametros(1000.0, 200.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.5, 0.0],\n",
    "    [0.5, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36db348c",
   "metadata": {},
   "source": [
    "Agora vamos considerar a função de estado-limite como sendo:\n",
    "$$\n",
    "g_3(X) = X_1 - \\frac{X_3}{X_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "049570e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "k",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "y_k",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "B",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "g(x)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "grad_g(x)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "||grad_g(x)||",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "g(y)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "54a3c3c4-1d60-403b-9b6b-3e10d573ab59",
       "rows": [
        [
         "0",
         "0",
         "[0. 0. 0.]",
         "0.0",
         "20.0",
         "[ 5.    -1.732 -4.   ]",
         "6.633",
         "20.0"
        ],
        [
         "1",
         "1",
         "[-2.273  0.787  1.818]",
         "3.015",
         "0.277",
         "[ 5.    -1.446 -3.826]",
         "6.46",
         "0.277"
        ],
        [
         "2",
         "2",
         "[-2.365  0.684  1.809]",
         "3.055",
         "-0.001",
         "[ 5.    -1.431 -3.848]",
         "6.47",
         "-0.001"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>[5.0, -1.732, -4.0]</td>\n",
       "      <td>6.633</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.273, 0.787, 1.818]</td>\n",
       "      <td>3.015</td>\n",
       "      <td>0.277</td>\n",
       "      <td>[5.0, -1.446, -3.826]</td>\n",
       "      <td>6.460</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.365, 0.684, 1.809]</td>\n",
       "      <td>3.055</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>[5.0, -1.431, -3.848]</td>\n",
       "      <td>6.470</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                     y_k      B    g(x)              grad_g(x)  \\\n",
       "0  0         [0.0, 0.0, 0.0]  0.000  20.000    [5.0, -1.732, -4.0]   \n",
       "1  1  [-2.273, 0.787, 1.818]  3.015   0.277  [5.0, -1.446, -3.826]   \n",
       "2  2  [-2.365, 0.684, 1.809]  3.055  -0.001  [5.0, -1.431, -3.848]   \n",
       "\n",
       "   ||grad_g(x)||    g(y)  \n",
       "0          6.633  20.000  \n",
       "1          6.460   0.277  \n",
       "2          6.470  -0.001  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias \n",
    "medias = np.array([40.0, 50.0, 1000.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = X1 - (X3 / X2)\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    # x é um vetor [X1, X2, X3]\n",
    "    return x[0] - (x[2] / x[1])\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return vetor_x_simbolico[0] - (vetor_x_simbolico[2] / vetor_x_simbolico[1]) \n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='normal', nome='sigma_y', simbolo='X1')\n",
    "X1.conjunto_parametros(40.0, 5.0) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='normal', nome='W', simbolo='X2')\n",
    "X2.conjunto_parametros(50.0, 2.5) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='normal', nome='M', simbolo='X3')\n",
    "X3.conjunto_parametros(1000.0, 200.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.5, 0.0],\n",
    "    [0.5, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e566c6",
   "metadata": {},
   "source": [
    "Por fim, vamos considerar a função de estado-limite como sendo:\n",
    "$$\n",
    "g_4(X) = X_2 - \\frac{X_3}{X_1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1046b106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "k",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "y_k",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "B",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "g(x)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "grad_g(x)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "||grad_g(x)||",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "g(y)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7b77d80d-ece7-40ad-8028-29153d469c88",
       "rows": [
        [
         "0",
         "0",
         "[0. 0. 0.]",
         "0.0",
         "25.0",
         "[ 3.125  1.083 -5.   ]",
         "5.995",
         "25.0"
        ],
        [
         "1",
         "1",
         "[-2.174 -0.753  3.478]",
         "4.17",
         "-6.341",
         "[ 8.652 -2.108 -6.389]",
         "10.96",
         "-6.341"
        ],
        [
         "2",
         "2",
         "[-2.384  0.581  1.761]",
         "3.02",
         "0.462",
         "[ 9.699 -2.713 -7.575]",
         "12.603",
         "0.462"
        ],
        [
         "3",
         "3",
         "[-2.351  0.658  1.836]",
         "3.055",
         "-0.001",
         "[ 9.85  -2.8   -7.592]",
         "12.748",
         "-0.001"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>[3.125, 1.083, -5.0]</td>\n",
       "      <td>5.995</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.174, -0.753, 3.478]</td>\n",
       "      <td>4.170</td>\n",
       "      <td>-6.341</td>\n",
       "      <td>[8.652, -2.108, -6.389]</td>\n",
       "      <td>10.960</td>\n",
       "      <td>-6.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-2.384, 0.581, 1.761]</td>\n",
       "      <td>3.020</td>\n",
       "      <td>0.462</td>\n",
       "      <td>[9.699, -2.713, -7.575]</td>\n",
       "      <td>12.603</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-2.351, 0.658, 1.836]</td>\n",
       "      <td>3.055</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>[9.85, -2.8, -7.592]</td>\n",
       "      <td>12.748</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                      y_k      B    g(x)                grad_g(x)  \\\n",
       "0  0          [0.0, 0.0, 0.0]  0.000  25.000     [3.125, 1.083, -5.0]   \n",
       "1  1  [-2.174, -0.753, 3.478]  4.170  -6.341  [8.652, -2.108, -6.389]   \n",
       "2  2   [-2.384, 0.581, 1.761]  3.020   0.462  [9.699, -2.713, -7.575]   \n",
       "3  3   [-2.351, 0.658, 1.836]  3.055  -0.001     [9.85, -2.8, -7.592]   \n",
       "\n",
       "   ||grad_g(x)||    g(y)  \n",
       "0          5.995  25.000  \n",
       "1         10.960  -6.341  \n",
       "2         12.603   0.462  \n",
       "3         12.748  -0.001  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias \n",
    "medias = np.array([40.0, 50.0, 1000.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = X2 - (X3 / X1) \n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    # x é um vetor [X1, X2, X3]\n",
    "    return x[1] - (x[2] / x[0])\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return vetor_x_simbolico[1] -  (vetor_x_simbolico[2] / vetor_x_simbolico[0])\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='normal', nome='sigma_y', simbolo='X1')\n",
    "X1.conjunto_parametros(40.0, 5.0) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='normal', nome='W', simbolo='X2')\n",
    "X2.conjunto_parametros(50.0, 2.5) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='normal', nome='M', simbolo='X3')\n",
    "X3.conjunto_parametros(1000.0, 200.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.5, 0.0],\n",
    "    [0.5, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5cfd8d",
   "metadata": {},
   "source": [
    "# Tarefa T6\n",
    "Neste exercício, vamos reproduzir o exercício 5 considerando distribuições log-normais das variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022ae24",
   "metadata": {},
   "source": [
    "Na resolução do exercício 6, vamos considerar inicialmente a seguinte função de estado limite: <br>\n",
    "$$\n",
    "g_2(X) = \\frac{X_1 X_2}{X_3} - 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c0e03e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.062, 0.025, 0.099]</td>\n",
       "      <td>0.120</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[0.249, 0.1, -0.396]</td>\n",
       "      <td>0.478</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-1.206, -0.452, 1.54]</td>\n",
       "      <td>2.008</td>\n",
       "      <td>0.253</td>\n",
       "      <td>[0.156, 0.063, -0.248]</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-1.485, -0.594, 2.294]</td>\n",
       "      <td>2.797</td>\n",
       "      <td>0.035</td>\n",
       "      <td>[0.129, 0.052, -0.205]</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-1.53, -0.614, 2.434]</td>\n",
       "      <td>2.939</td>\n",
       "      <td>0.001</td>\n",
       "      <td>[0.125, 0.05, -0.198]</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                      y_k      B   g(x)               grad_g(x)  \\\n",
       "0  0    [0.062, 0.025, 0.099]  0.120  1.000    [0.249, 0.1, -0.396]   \n",
       "1  1   [-1.206, -0.452, 1.54]  2.008  0.253  [0.156, 0.063, -0.248]   \n",
       "2  2  [-1.485, -0.594, 2.294]  2.797  0.035  [0.129, 0.052, -0.205]   \n",
       "3  3   [-1.53, -0.614, 2.434]  2.939  0.001   [0.125, 0.05, -0.198]   \n",
       "\n",
       "   ||grad_g(x)||   g(y)  \n",
       "0          0.478  1.000  \n",
       "1          0.300  0.253  \n",
       "2          0.248  0.035  \n",
       "3          0.239  0.001  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias \n",
    "medias = np.array([40.0, 50.0, 1000.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = ((X1 * X2) / X3) - 1\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    return ((x[0] * x[1]) / x[2]) - 1\n",
    "\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return ((vetor_x_simbolico[0] *  vetor_x_simbolico[1]) / vetor_x_simbolico[2]) - 1\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='lognormal', nome='sigma_y', simbolo='X1')\n",
    "X1.calculo_parametros(40.0, 5.0) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='lognormal', nome='W', simbolo='X2')\n",
    "X2.calculo_parametros(50.0, 2.5) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='lognormal', nome='M', simbolo='X3')\n",
    "X3.calculo_parametros(1000.0, 200.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae269193",
   "metadata": {},
   "source": [
    "Agora vamos considerar a função de estado-limite como sendo:\n",
    "$$\n",
    "g_3(X) = X_1 - \\frac{X_3}{X_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0cc578a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.062, 0.025, 0.099]</td>\n",
       "      <td>0.120</td>\n",
       "      <td>20.000</td>\n",
       "      <td>[4.981, 0.999, -3.961]</td>\n",
       "      <td>6.442</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.889, -0.49, 1.65]</td>\n",
       "      <td>3.363</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>[3.449, 1.394, -5.525]</td>\n",
       "      <td>6.661</td>\n",
       "      <td>-0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-1.626, -0.615, 2.381]</td>\n",
       "      <td>2.948</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>[4.037, 1.621, -6.426]</td>\n",
       "      <td>7.760</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-1.53, -0.615, 2.436]</td>\n",
       "      <td>2.942</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[4.084, 1.639, -6.496]</td>\n",
       "      <td>7.847</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                      y_k      B    g(x)               grad_g(x)  \\\n",
       "0  0    [0.062, 0.025, 0.099]  0.120  20.000  [4.981, 0.999, -3.961]   \n",
       "1  1    [-2.889, -0.49, 1.65]  3.363  -0.201  [3.449, 1.394, -5.525]   \n",
       "2  2  [-1.626, -0.615, 2.381]  2.948  -0.028  [4.037, 1.621, -6.426]   \n",
       "3  3   [-1.53, -0.615, 2.436]  2.942   0.000  [4.084, 1.639, -6.496]   \n",
       "\n",
       "   ||grad_g(x)||    g(y)  \n",
       "0          6.442  20.000  \n",
       "1          6.661  -0.201  \n",
       "2          7.760  -0.028  \n",
       "3          7.847   0.000  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias \n",
    "medias = np.array([40.0, 50.0, 1000.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = X1 - (X3 / X2)\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    return x[0] - (x[2] / x[1]) \n",
    "\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return vetor_x_simbolico[0] - (vetor_x_simbolico[2] / vetor_x_simbolico[1]) \n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='lognormal', nome='sigma_y', simbolo='X1')\n",
    "X1.calculo_parametros(40.0, 5.0) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='lognormal', nome='W', simbolo='X2')\n",
    "X2.calculo_parametros(50.0, 2.5) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='lognormal', nome='M', simbolo='X3')\n",
    "X3.calculo_parametros(1000.0, 200.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d721952",
   "metadata": {},
   "source": [
    "Por fim, vamos considerar a função de estado-limite como sendo:\n",
    "$$\n",
    "g_4(X) = X_2 - \\frac{X_3}{X_1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9a2a4d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.062, 0.025, 0.099]</td>\n",
       "      <td>0.120</td>\n",
       "      <td>25.000</td>\n",
       "      <td>[3.113, 2.498, -4.951]</td>\n",
       "      <td>6.360</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.244, -1.625, 2.447]</td>\n",
       "      <td>3.697</td>\n",
       "      <td>-6.999</td>\n",
       "      <td>[6.605, 2.301, -10.504]</td>\n",
       "      <td>12.620</td>\n",
       "      <td>-6.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-1.574, -0.567, 2.458]</td>\n",
       "      <td>2.973</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>[6.089, 2.426, -9.685]</td>\n",
       "      <td>11.694</td>\n",
       "      <td>-0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-1.532, -0.61, 2.437]</td>\n",
       "      <td>2.942</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>[6.032, 2.42, -9.593]</td>\n",
       "      <td>11.587</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                      y_k      B    g(x)                grad_g(x)  \\\n",
       "0  0    [0.062, 0.025, 0.099]  0.120  25.000   [3.113, 2.498, -4.951]   \n",
       "1  1  [-2.244, -1.625, 2.447]  3.697  -6.999  [6.605, 2.301, -10.504]   \n",
       "2  2  [-1.574, -0.567, 2.458]  2.973  -0.360   [6.089, 2.426, -9.685]   \n",
       "3  3   [-1.532, -0.61, 2.437]  2.942  -0.002    [6.032, 2.42, -9.593]   \n",
       "\n",
       "   ||grad_g(x)||    g(y)  \n",
       "0          6.360  25.000  \n",
       "1         12.620  -6.999  \n",
       "2         11.694  -0.360  \n",
       "3         11.587  -0.002  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias \n",
    "medias = np.array([40.0, 50.0, 1000.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = X2 - (X3 / X1)\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    return x[1] - (x[2] / x[0]) \n",
    "\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return vetor_x_simbolico[1] - (vetor_x_simbolico[2] / vetor_x_simbolico[0]) \n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='lognormal', nome='sigma_y', simbolo='X1')\n",
    "X1.calculo_parametros(40.0, 5.0) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='lognormal', nome='W', simbolo='X2')\n",
    "X2.calculo_parametros(50.0, 2.5) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='lognormal', nome='M', simbolo='X3')\n",
    "X3.calculo_parametros(1000.0, 200.0)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f47cde",
   "metadata": {},
   "source": [
    "# Tarefa 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910ce40",
   "metadata": {},
   "source": [
    "Reprodução do exemplo 7 do livro, para validação do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ca758c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0647, 0.0, 0.1773]</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>1.2789</td>\n",
       "      <td>[0.431, -0.105, -0.239]</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>1.2789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.6091, 0.5348, 1.0577]</td>\n",
       "      <td>2.8657</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>[0.3049, -0.105, -0.3316]</td>\n",
       "      <td>0.4626</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-1.7615, 0.5901, 1.7624]</td>\n",
       "      <td>2.5607</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>[0.3402, -0.105, -0.4304]</td>\n",
       "      <td>0.5586</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-1.551, 0.4778, 1.952]</td>\n",
       "      <td>2.5385</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[0.3496, -0.105, -0.4602]</td>\n",
       "      <td>0.5874</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-1.5105, 0.4536, 1.9882]</td>\n",
       "      <td>2.5378</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[0.3515, -0.105, -0.466]</td>\n",
       "      <td>0.5931</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                        y_k       B    g(x)                  grad_g(x)  \\\n",
       "0  0      [0.0647, 0.0, 0.1773]  0.1888  1.2789    [0.431, -0.105, -0.239]   \n",
       "1  1  [-2.6091, 0.5348, 1.0577]  2.8657 -0.0000  [0.3049, -0.105, -0.3316]   \n",
       "2  2  [-1.7615, 0.5901, 1.7624]  2.5607 -0.0000  [0.3402, -0.105, -0.4304]   \n",
       "3  3    [-1.551, 0.4778, 1.952]  2.5385  0.0000  [0.3496, -0.105, -0.4602]   \n",
       "4  4  [-1.5105, 0.4536, 1.9882]  2.5378  0.0000   [0.3515, -0.105, -0.466]   \n",
       "\n",
       "   ||grad_g(x)||    g(y)  \n",
       "0         0.5039  1.2789  \n",
       "1         0.4626 -0.0000  \n",
       "2         0.5586 -0.0000  \n",
       "3         0.5874 -0.0000  \n",
       "4         0.5931 -0.0001  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Construção do vetor de médias \n",
    "medias = np.array([3.3289, 1.05, 1.0])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = X1 - (X2 + X3)\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    return x[0] - (x[1] + x[2]) \n",
    "\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return vetor_x_simbolico[0] - (vetor_x_simbolico[1] + vetor_x_simbolico[2]) \n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='lognormal', nome='R', simbolo='X1')\n",
    "X1.calculo_parametros(3.3289, 0.4328) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='normal', nome='D', simbolo='X2')\n",
    "X2.conjunto_parametros(1.05, 0.105) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='gumbel_max', nome='L', simbolo='X3')\n",
    "X3.calculo_parametros(1.0, 0.25)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 4) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbdb6a",
   "metadata": {},
   "source": [
    "Uma vez que houve a validação da estrutura através do exemplo 7, vamos resolver o exercício 6 do livro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ee8c6b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0647, 0.0, 0.1773]</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>4.887</td>\n",
       "      <td>[1.416, -0.105, -1.1952]</td>\n",
       "      <td>1.8560</td>\n",
       "      <td>4.8870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.4179, 0.1526, 1.4081]</td>\n",
       "      <td>2.8022</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>[1.0268, -0.105, -1.891]</td>\n",
       "      <td>2.1543</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-1.237, 0.1168, 2.0277]</td>\n",
       "      <td>2.3780</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>[1.1964, -0.105, -2.3622]</td>\n",
       "      <td>2.6500</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-1.0703, 0.0939, 2.1131]</td>\n",
       "      <td>2.3705</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>[1.2222, -0.105, -2.4311]</td>\n",
       "      <td>2.7231</td>\n",
       "      <td>-0.0008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k                        y_k       B   g(x)                  grad_g(x)  \\\n",
       "0  0      [0.0647, 0.0, 0.1773]  0.1888  4.887   [1.416, -0.105, -1.1952]   \n",
       "1  1  [-2.4179, 0.1526, 1.4081]  2.8022 -0.000   [1.0268, -0.105, -1.891]   \n",
       "2  2   [-1.237, 0.1168, 2.0277]  2.3780 -0.000  [1.1964, -0.105, -2.3622]   \n",
       "3  3  [-1.0703, 0.0939, 2.1131]  2.3705 -0.000  [1.2222, -0.105, -2.4311]   \n",
       "\n",
       "   ||grad_g(x)||    g(y)  \n",
       "0         1.8560  4.8870  \n",
       "1         2.1543  0.0000  \n",
       "2         2.6500  0.0000  \n",
       "3         2.7231 -0.0008  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "medias = np.array([10.937, 1.05, 5])\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1, X2, X3 = sp.symbols('X1 X2 X3')\n",
    "vetor_simbolico_x = [X1, X2, X3]\n",
    "g_sym_function = X1 - (X2 + X3)\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    return x[0] - (x[1] + x[2]) \n",
    "\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1, Y2, Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "     return vetor_x_simbolico[0] - (vetor_x_simbolico[1] + vetor_x_simbolico[2]) \n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='lognormal', nome='R', simbolo='X1')\n",
    "X1.calculo_parametros(10.937, 1.422) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='normal', nome='D', simbolo='X2')\n",
    "X2.conjunto_parametros(1.05, 0.105) \n",
    "\n",
    "X3 = variavel_aleatoria(distribuicao='gumbel_max', nome='L', simbolo='X3')\n",
    "X3.calculo_parametros(5.0, 1.25)\n",
    "\n",
    "vetor_va = [X1, X2, X3]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = medias\n",
    "ponto_projeto_obj = Ponto_projeto(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 4) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e1fc7e",
   "metadata": {},
   "source": [
    "# Tarefa T8 \n",
    "Para a resolução dos problemas P1 e P2 vamos utilizar o algoritmo abaixo com o método de busca sendo o *iHRLF*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62398ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import sympy as sp\n",
    "from sympy.utilities.lambdify import lambdify\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "class Ponto_projeto_iHRLF:\n",
    "    def __init__(self, vx_obj, g_fun_numerica_x, vetor_simbolico_y, g_y_simbolico, g_sym_fun, vetor_simbolico, x_inicial, max_iter=100):\n",
    "\n",
    "        # Inicialização das variáveis\n",
    "        self.vx_obj = vx_obj \n",
    "        self.g_fun_x_num = g_fun_numerica_x\n",
    "        self.vetor_simbolico_y = vetor_simbolico_y\n",
    "        self.g_y_simbolico = g_y_simbolico\n",
    "        self.grad_g_x_fun = self.calcular_gradiente_simbolico_x(g_sym_fun, vetor_simbolico)\n",
    "        self.x_estrela_atual = x_inicial\n",
    "        self.max_iter = max_iter\n",
    "        self.historico = []\n",
    "\n",
    "    # Atualização das matrizes de média e desvio padrão equivalente\n",
    "    def normal_equivalente_no_ponto (self, vetor_x: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "        mu_neq_lista = []\n",
    "        sigma_neq_lista = []\n",
    "\n",
    "        for i, va in enumerate(self.vx_obj.vetor_va_cust):\n",
    "            x_i = vetor_x[i]\n",
    "\n",
    "            cdf_xi = va.CDF(x_i)\n",
    "            pdf_xi = va.PDF(x_i)\n",
    "\n",
    "            z_i = sc.stats.norm.ppf(cdf_xi)\n",
    "            phi_zi = sc.stats.norm.pdf(z_i)\n",
    "\n",
    "            sigma_neq_i = phi_zi / pdf_xi\n",
    "            mu_neq_i = x_i - (z_i * sigma_neq_i)\n",
    "\n",
    "            mu_neq_lista.append(mu_neq_i)\n",
    "            sigma_neq_lista.append(sigma_neq_i)\n",
    "\n",
    "        return np.array(mu_neq_lista), np.diag(sigma_neq_lista)\n",
    "    \n",
    "    # Calculo do gradiente numérico da função g(x) a partir da função simbólica fornecida paara g(x)\n",
    "    def calcular_gradiente_simbolico_x(self, g_sym:sp.Expr, vetor_simbolico: List[sp.Symbol]) -> Callable:\n",
    "        \n",
    "        grad_g_sym = [sp.diff(g_sym, x_i) for x_i in vetor_simbolico]\n",
    "\n",
    "        grad_g_numeric = lambdify(vetor_simbolico, grad_g_sym, 'numpy')\n",
    "        \n",
    "        def grad_g_x_numerico(x_vals: np.ndarray) -> np.ndarray:\n",
    "            return np.array(grad_g_numeric(*x_vals))\n",
    "        \n",
    "        return grad_g_x_numerico\n",
    "     \n",
    "    # Estrutura principal de calculo e iteração em busca do ponto de projeto\n",
    "    def execution (self,):\n",
    "\n",
    "        historico = [] # Vetor que armazena o histórico de iterações\n",
    "\n",
    "        for k in range(self.max_iter):\n",
    "            \n",
    "            # Ponto de projeto x* para a iteração k\n",
    "            x_k = self.x_estrela_atual \n",
    "\n",
    "            # Atualização das matrizes de média e desvio padrão equivalentes para o ponto x_k\n",
    "            # Calculo dos Jacobianos da transformação X -> Z\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            vetor_simbolico_y = self.vetor_simbolico_y\n",
    "            vetor_simbolico_x_calc = (J_xy @ vetor_simbolico_y) + mu_neq\n",
    "            g_y_simbolico = self.g_y_simbolico(vetor_simbolico_x_calc)\n",
    "            g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "            \n",
    "            def calculo_g_y(vetor_y):\n",
    "                return g_y_numerico(*vetor_y)\n",
    "            \n",
    "            # Trandformação do ponto xk -> yk\n",
    "            y_k = J_yx @ (x_k - mu_neq)\n",
    "\n",
    "            # Calculo do índice de confiabilidade para o ponto yk\n",
    "            beta_k = np.linalg.norm(y_k)\n",
    "            \n",
    "            # Avaliação das funções g(x) em x_k e g(y) em y_k\n",
    "            g_x = self.g_fun_x_num(x_k)\n",
    "            g_y = calculo_g_y(y_k)\n",
    "\n",
    "            if k == 0:\n",
    "                g_y_zero = g_y\n",
    "\n",
    "            # Calculo do gradiente de g(x) no espaço de projeto X em x_k\n",
    "            grad_g_x = self.grad_g_x_fun(x_k)\n",
    "\n",
    "            # Calculo do gradiente de g(y) em y_k a partir da transformação X -> Y\n",
    "            grad_g_y = (J_xy.T) @ grad_g_x\n",
    "\n",
    "            # Calculo dos coeficientes de sensibilidade\n",
    "            alpha = grad_g_y / np.linalg.norm(grad_g_y)\n",
    "\n",
    "            historico.append([\n",
    "                k, \n",
    "                y_k, \n",
    "                beta_k, \n",
    "                g_x, \n",
    "                grad_g_y, \n",
    "                np.linalg.norm(grad_g_y),\n",
    "                g_y,\n",
    "                x_k\n",
    "            ])  \n",
    "\n",
    "            gamma = 2.0 \n",
    "            \n",
    "            # Direção de Busca d_k \n",
    "            d_k = (((1 / (np.linalg.norm(grad_g_y)**2)) * ((grad_g_y.T @ y_k) - g_y)) * grad_g_y) - y_k\n",
    "            \n",
    "            if np.abs(g_y) >= np.abs(1e-3 * g_y_zero):\n",
    "            \n",
    "                func_1 = np.linalg.norm(y_k) / np.linalg.norm(grad_g_y)\n",
    "                func_2 = (0.5 * (np.linalg.norm(y_k + d_k)**2)) / np.abs(g_y)\n",
    "                c_k = gamma * np.maximum(func_1, func_2)\n",
    "            else:\n",
    "                c_k = gamma * np.linalg.norm(y_k) / np.linalg.norm(grad_g_y)\n",
    "\n",
    "                #Busca Linear \n",
    "            def m(y_vec, g_y_val=None):\n",
    "                if g_y_val is None:\n",
    "                    g_y_val = calculo_g_y(y_vec)\n",
    "                return 0.5 * (np.linalg.norm(y_vec)**2) + (c_k * np.abs(g_y_val))\n",
    "\n",
    "            # gradiente do mérito no ponto y_k\n",
    "            sign_g = np.sign(g_y) if g_y != 0 else 1.0\n",
    "            grad_m_y_k = y_k + (c_k * grad_g_y * sign_g)\n",
    "\n",
    "            # Armijo\n",
    "            lambda_k = 1.0\n",
    "            rho = 0.5 #b\n",
    "            sigma = 0.1 #a\n",
    "            backtracks = 0\n",
    "            m_y = m(y_k, g_y)\n",
    "            grad_m_dot_d = float(grad_m_y_k.T @ d_k)\n",
    "\n",
    "            while backtracks < 50:\n",
    "                y_trial = y_k + lambda_k * d_k\n",
    "                g_y_trial = calculo_g_y(y_trial)\n",
    "                m_trial = m(y_trial, g_y_trial)\n",
    "                rhs = m_y + sigma * lambda_k * grad_m_dot_d\n",
    "\n",
    "                if m_trial <= rhs:\n",
    "                    break\n",
    "                \n",
    "                lambda_k *= rho\n",
    "                backtracks += 1\n",
    "\n",
    "            #Atualização do Ponto\n",
    "            y_k_mais_1 = y_k + lambda_k * d_k\n",
    "                \n",
    "            # Calculo do ponto x_k+1 a partir da tranformação Y -> X\n",
    "            x_k_mais_1 = (J_xy @ y_k_mais_1) + mu_neq\n",
    "\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k_mais_1)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            vetor_simbolico_y = self.vetor_simbolico_y\n",
    "            vetor_simbolico_x_calc = (J_xy @ vetor_simbolico_y) + mu_neq\n",
    "            g_y_simbolico = self.g_y_simbolico(vetor_simbolico_x_calc)\n",
    "            g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "            def calculo_g_y(vetor_y):\n",
    "                return g_y_numerico(*vetor_y)\n",
    "\n",
    "            # Verificação da convergência do ponto y_k+1\n",
    "            ep = 1e-3    \n",
    "            g_x_mais_1 = self.g_fun_x_num(x_k_mais_1)\n",
    "            grad_x_mais_1 = self.grad_g_x_fun(x_k_mais_1)\n",
    "\n",
    "            g_y_mais_1 = calculo_g_y(y_k_mais_1)\n",
    "            grad_y_mais_1 = (J_xy.T) @ grad_x_mais_1\n",
    "\n",
    "            alpha_mais_1 = grad_y_mais_1 / np.linalg.norm(grad_y_mais_1)\n",
    "\n",
    "            verificador = 1 - (abs((grad_y_mais_1.T @ y_k_mais_1) / ((np.linalg.norm(grad_y_mais_1)) * (np.linalg.norm(y_k_mais_1)))))\n",
    "            \n",
    "            if verificador < ep:\n",
    "                if abs(g_y_mais_1) < abs (ep * g_y_zero):\n",
    "\n",
    "                    historico.append([\n",
    "                        k+1, \n",
    "                        y_k_mais_1, \n",
    "                        np.linalg.norm(y_k_mais_1), \n",
    "                        g_x_mais_1, \n",
    "                        grad_y_mais_1, \n",
    "                        np.linalg.norm(grad_y_mais_1),\n",
    "                        g_y_mais_1,\n",
    "                        x_k_mais_1\n",
    "                    ])  \n",
    "\n",
    "                    break\n",
    "                else:\n",
    "                    self.x_estrela_atual = x_k_mais_1 \n",
    "            else:\n",
    "                self.x_estrela_atual = x_k_mais_1\n",
    "\n",
    "                if k == self.max_iter - 1:\n",
    "                    print(f\"Não convergiu em {self.max_iter} iterações\")\n",
    "    \n",
    "        return historico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b6cfd",
   "metadata": {},
   "source": [
    " Exercício P1 considerando *f=1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b26cc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "      <th>x_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-2.326]</td>\n",
       "      <td>2.326</td>\n",
       "      <td>2.401</td>\n",
       "      <td>[-0.261]</td>\n",
       "      <td>0.261</td>\n",
       "      <td>2.401</td>\n",
       "      <td>[0.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.659]</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.600</td>\n",
       "      <td>[-1.573]</td>\n",
       "      <td>1.573</td>\n",
       "      <td>0.600</td>\n",
       "      <td>[0.255]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.312]</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.150</td>\n",
       "      <td>[-0.931]</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.150</td>\n",
       "      <td>[0.378]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.154]</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.038</td>\n",
       "      <td>[-0.483]</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.038</td>\n",
       "      <td>[0.439]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.077]</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.009</td>\n",
       "      <td>[-0.244]</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.009</td>\n",
       "      <td>[0.469]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[-0.038]</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.002</td>\n",
       "      <td>[-0.122]</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.002</td>\n",
       "      <td>[0.485]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k       y_k      B   g(x) grad_g(x)  ||grad_g(x)||   g(y)      x_k\n",
       "0  0  [-2.326]  2.326  2.401  [-0.261]          0.261  2.401   [0.01]\n",
       "1  1  [-0.659]  0.659  0.600  [-1.573]          1.573  0.600  [0.255]\n",
       "2  2  [-0.312]  0.312  0.150  [-0.931]          0.931  0.150  [0.378]\n",
       "3  3  [-0.154]  0.154  0.038  [-0.483]          0.483  0.038  [0.439]\n",
       "4  4  [-0.077]  0.077  0.009  [-0.244]          0.244  0.009  [0.469]\n",
       "5  5  [-0.038]  0.038  0.002  [-0.122]          0.122  0.002  [0.485]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1,f,P,L = sp.symbols('X1 f P L')\n",
    "vetor_simbolico_x = [X1]\n",
    "f = 1\n",
    "P = 1\n",
    "L = 1\n",
    "g_sym_function = ((f * P * L) / 4) - (P * (X1 - ((X1**2) / L)))\n",
    "\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "\n",
    "    f = 1\n",
    "    P = 1\n",
    "    L = 1\n",
    "    return ((f * P * L) / 4) - (P * (x[0] - ((x[0]**2) / L)))\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1,f,P,L = sp.symbols('Y1 f P L')\n",
    "vetor_simbolico_y = [Y1]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "    f = 1\n",
    "    P = 1\n",
    "    L = 1\n",
    "    return ((f * P * L) / 4) - (P * (vetor_x_simbolico[0] - ((vetor_x_simbolico[0]**2) / L)))\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='uniforme', nome='Posicao', simbolo='X1')\n",
    "X1.conjunto_parametros(0, 1) \n",
    "\n",
    "vetor_va = [X1]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((1, 1)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial \n",
    "x_start = np.array([0.01])\n",
    "ponto_projeto_obj = Ponto_projeto_iHRLF(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)', 'x_k' ])\n",
    "tabela\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b4759",
   "metadata": {},
   "source": [
    " Exercício P1 considerando *f=0.5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3565c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>y_k</th>\n",
       "      <th>B</th>\n",
       "      <th>g(x)</th>\n",
       "      <th>grad_g(x)</th>\n",
       "      <th>||grad_g(x)||</th>\n",
       "      <th>g(y)</th>\n",
       "      <th>x_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-2.326]</td>\n",
       "      <td>2.326</td>\n",
       "      <td>0.115</td>\n",
       "      <td>[-0.026]</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.115</td>\n",
       "      <td>[0.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-1.139]</td>\n",
       "      <td>1.139</td>\n",
       "      <td>0.014</td>\n",
       "      <td>[-0.155]</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.014</td>\n",
       "      <td>[0.127]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-1.054]</td>\n",
       "      <td>1.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[-0.162]</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[0.146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-1.052]</td>\n",
       "      <td>1.052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[-0.162]</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>[0.146]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k       y_k      B   g(x) grad_g(x)  ||grad_g(x)||   g(y)      x_k\n",
       "0  0  [-2.326]  2.326  0.115  [-0.026]          0.026  0.115   [0.01]\n",
       "1  1  [-1.139]  1.139  0.014  [-0.155]          0.155  0.014  [0.127]\n",
       "2  2  [-1.054]  1.054  0.000  [-0.162]          0.162  0.000  [0.146]\n",
       "3  3  [-1.052]  1.052  0.000  [-0.162]          0.162 -0.000  [0.146]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1,f,P,L = sp.symbols('X1 f P L')\n",
    "vetor_simbolico_x = [X1]\n",
    "f = 0.5\n",
    "P = 1\n",
    "L = 1\n",
    "g_sym_function = ((f * P * L) / 4) - (P * (X1 - ((X1**2) / L)))\n",
    "\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "\n",
    "    f = 0.5\n",
    "    P = 1\n",
    "    L = 1\n",
    "    return ((f * P * L) / 4) - (P * (x[0] - ((x[0]**2) / L)))\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1,f,P,L = sp.symbols('Y1 f P L')\n",
    "vetor_simbolico_y = [Y1]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "    f = 0.5\n",
    "    P = 1\n",
    "    L = 1\n",
    "    return ((f * P * L) / 4) - (P * (vetor_x_simbolico[0] - ((vetor_x_simbolico[0]**2) / L)))\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='uniforme', nome='Posicao', simbolo='X1')\n",
    "X1.conjunto_parametros(0, 1) \n",
    "\n",
    "vetor_va = [X1]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((1, 1)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial \n",
    "x_start = np.array([0.01])\n",
    "ponto_projeto_obj = Ponto_projeto_iHRLF(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)', 'x_k' ])\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0a361",
   "metadata": {},
   "source": [
    "Exercício P2 <br>\n",
    "Para a resolução do exercicio, vamos considerar o algoritmo iHLRF com os parêmetros a=0.5 e b=0.5 e $\\rho_{12}=0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0ddebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import sympy as sp\n",
    "from sympy.utilities.lambdify import lambdify\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "class Ponto_projeto_iHRLF_mod:\n",
    "    def __init__(self, vx_obj, g_fun_numerica_x, vetor_simbolico_y, g_y_simbolico, g_sym_fun, vetor_simbolico, x_inicial, max_iter=100):\n",
    "\n",
    "        # Inicialização das variáveis\n",
    "        self.vx_obj = vx_obj \n",
    "        self.g_fun_x_num = g_fun_numerica_x\n",
    "        self.vetor_simbolico_y = vetor_simbolico_y\n",
    "        self.g_y_simbolico = g_y_simbolico\n",
    "        self.grad_g_x_fun = self.calcular_gradiente_simbolico_x(g_sym_fun, vetor_simbolico)\n",
    "        self.x_estrela_atual = x_inicial\n",
    "        self.max_iter = max_iter\n",
    "        self.historico = []\n",
    "\n",
    "    # Atualização das matrizes de média e desvio padrão equivalente\n",
    "    def normal_equivalente_no_ponto (self, vetor_x: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "        mu_neq_lista = []\n",
    "        sigma_neq_lista = []\n",
    "\n",
    "        for i, va in enumerate(self.vx_obj.vetor_va_cust):\n",
    "            x_i = vetor_x[i]\n",
    "\n",
    "            cdf_xi = va.CDF(x_i)\n",
    "            pdf_xi = va.PDF(x_i)\n",
    "\n",
    "            z_i = sc.stats.norm.ppf(cdf_xi)\n",
    "            phi_zi = sc.stats.norm.pdf(z_i)\n",
    "\n",
    "            sigma_neq_i = phi_zi / pdf_xi\n",
    "            mu_neq_i = x_i - (z_i * sigma_neq_i)\n",
    "\n",
    "            mu_neq_lista.append(mu_neq_i)\n",
    "            sigma_neq_lista.append(sigma_neq_i)\n",
    "\n",
    "        return np.array(mu_neq_lista), np.diag(sigma_neq_lista)\n",
    "    \n",
    "    # Calculo do gradiente numérico da função g(x) a partir da função simbólica fornecida paara g(x)\n",
    "    def calcular_gradiente_simbolico_x(self, g_sym:sp.Expr, vetor_simbolico: List[sp.Symbol]) -> Callable:\n",
    "        \n",
    "        grad_g_sym = [sp.diff(g_sym, x_i) for x_i in vetor_simbolico]\n",
    "\n",
    "        grad_g_numeric = lambdify(vetor_simbolico, grad_g_sym, 'numpy')\n",
    "        \n",
    "        def grad_g_x_numerico(x_vals: np.ndarray) -> np.ndarray:\n",
    "            return np.array(grad_g_numeric(*x_vals))\n",
    "        \n",
    "        return grad_g_x_numerico\n",
    "     \n",
    "    # Estrutura principal de calculo e iteração em busca do ponto de projeto\n",
    "    def execution (self,):\n",
    "\n",
    "        historico = [] # Vetor que armazena o histórico de iterações\n",
    "\n",
    "        for k in range(self.max_iter):\n",
    "            \n",
    "            # Ponto de projeto x* para a iteração k\n",
    "            x_k = self.x_estrela_atual \n",
    "\n",
    "            # Atualização das matrizes de média e desvio padrão equivalentes para o ponto x_k\n",
    "            # Calculo dos Jacobianos da transformação X -> Z\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            vetor_simbolico_y = self.vetor_simbolico_y\n",
    "            vetor_simbolico_x_calc = (J_xy @ vetor_simbolico_y) + mu_neq\n",
    "            g_y_simbolico = self.g_y_simbolico(vetor_simbolico_x_calc)\n",
    "            g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "            \n",
    "            def calculo_g_y(vetor_y):\n",
    "                return g_y_numerico(*vetor_y)\n",
    "            \n",
    "            # Trandformação do ponto xk -> yk\n",
    "            y_k = J_yx @ (x_k - mu_neq)\n",
    "\n",
    "            # Calculo do índice de confiabilidade para o ponto yk\n",
    "            beta_k = np.linalg.norm(y_k)\n",
    "            \n",
    "            # Avaliação das funções g(x) em x_k e g(y) em y_k\n",
    "            g_x = self.g_fun_x_num(x_k)\n",
    "            g_y = calculo_g_y(y_k)\n",
    "\n",
    "            if k == 0:\n",
    "                g_y_zero = g_y\n",
    "\n",
    "            # Calculo do gradiente de g(x) no espaço de projeto X em x_k\n",
    "            grad_g_x = self.grad_g_x_fun(x_k)\n",
    "\n",
    "            # Calculo do gradiente de g(y) em y_k a partir da transformação X -> Y\n",
    "            grad_g_y = (J_xy.T) @ grad_g_x\n",
    "\n",
    "            # Calculo dos coeficientes de sensibilidade\n",
    "            alpha = grad_g_y / np.linalg.norm(grad_g_y)\n",
    "\n",
    "            historico.append([\n",
    "                k, \n",
    "                y_k, \n",
    "                beta_k, \n",
    "                g_x, \n",
    "                grad_g_y, \n",
    "                np.linalg.norm(grad_g_y),\n",
    "                g_y,\n",
    "                x_k\n",
    "            ])  \n",
    "\n",
    "            gamma = 2.0 \n",
    "            \n",
    "            # Direção de Busca d_k \n",
    "            d_k = (((1 / (np.linalg.norm(grad_g_y)**2)) * ((grad_g_y.T @ y_k) - g_y)) * grad_g_y) - y_k\n",
    "            \n",
    "            if np.abs(g_y) >= np.abs(1e-3 * g_y_zero):\n",
    "            \n",
    "                func_1 = np.linalg.norm(y_k) / np.linalg.norm(grad_g_y)\n",
    "                func_2 = (0.5 * (np.linalg.norm(y_k + d_k)**2)) / np.abs(g_y)\n",
    "                c_k = gamma * np.maximum(func_1, func_2)\n",
    "            else:\n",
    "                c_k = gamma * np.linalg.norm(y_k) / np.linalg.norm(grad_g_y)\n",
    "\n",
    "                #Busca Linear \n",
    "            def m(y_vec, g_y_val=None):\n",
    "                if g_y_val is None:\n",
    "                    g_y_val = calculo_g_y(y_vec)\n",
    "                return 0.5 * (np.linalg.norm(y_vec)**2) + (c_k * np.abs(g_y_val))\n",
    "\n",
    "            # gradiente do mérito no ponto y_k\n",
    "            sign_g = np.sign(g_y) if g_y != 0 else 1.0\n",
    "            grad_m_y_k = y_k + (c_k * grad_g_y * sign_g)\n",
    "\n",
    "            # Armijo\n",
    "            lambda_k = 1.0\n",
    "            rho = 0.5 #b\n",
    "            sigma = 0.5 #a\n",
    "            backtracks = 0\n",
    "            m_y = m(y_k, g_y)\n",
    "            grad_m_dot_d = float(grad_m_y_k.T @ d_k)\n",
    "\n",
    "            while backtracks < 50:\n",
    "                y_trial = y_k + lambda_k * d_k\n",
    "                g_y_trial = calculo_g_y(y_trial)\n",
    "                m_trial = m(y_trial, g_y_trial)\n",
    "                rhs = m_y + sigma * lambda_k * grad_m_dot_d\n",
    "\n",
    "                if m_trial <= rhs:\n",
    "                    break\n",
    "                \n",
    "                lambda_k *= rho\n",
    "                backtracks += 1\n",
    "\n",
    "            #Atualização do Ponto\n",
    "            y_k_mais_1 = y_k + lambda_k * d_k\n",
    "                \n",
    "            # Calculo do ponto x_k+1 a partir da tranformação Y -> X\n",
    "            x_k_mais_1 = (J_xy @ y_k_mais_1) + mu_neq\n",
    "\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k_mais_1)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            vetor_simbolico_y = self.vetor_simbolico_y\n",
    "            vetor_simbolico_x_calc = (J_xy @ vetor_simbolico_y) + mu_neq\n",
    "            g_y_simbolico = self.g_y_simbolico(vetor_simbolico_x_calc)\n",
    "            g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "            def calculo_g_y(vetor_y):\n",
    "                return g_y_numerico(*vetor_y)\n",
    "\n",
    "            # Verificação da convergência do ponto y_k+1\n",
    "            ep = 1e-3    \n",
    "            g_x_mais_1 = self.g_fun_x_num(x_k_mais_1)\n",
    "            grad_x_mais_1 = self.grad_g_x_fun(x_k_mais_1)\n",
    "\n",
    "            g_y_mais_1 = calculo_g_y(y_k_mais_1)\n",
    "            grad_y_mais_1 = (J_xy.T) @ grad_x_mais_1\n",
    "\n",
    "            beta_k_mais_1 = np.linalg.norm(y_k_mais_1)\n",
    "            alpha_mais_1 = grad_y_mais_1 / np.linalg.norm(grad_y_mais_1)\n",
    "\n",
    "            verificador = 1 - (abs((grad_y_mais_1.T @ y_k_mais_1) / ((np.linalg.norm(grad_y_mais_1)) * (np.linalg.norm(y_k_mais_1)))))\n",
    "            \n",
    "            if verificador < ep:\n",
    "                if abs(g_y_mais_1) < abs (ep * g_y_zero):\n",
    "\n",
    "                    historico.append([\n",
    "                        k+1, \n",
    "                        y_k_mais_1, \n",
    "                        beta_k_mais_1, \n",
    "                        g_x_mais_1, \n",
    "                        grad_y_mais_1, \n",
    "                        np.linalg.norm(grad_y_mais_1),\n",
    "                        g_y_mais_1,\n",
    "                        x_k_mais_1\n",
    "                    ])  \n",
    "\n",
    "                    break\n",
    "                else:\n",
    "                    self.x_estrela_atual = x_k_mais_1 \n",
    "            else:\n",
    "                self.x_estrela_atual = x_k_mais_1\n",
    "\n",
    "                if k == self.max_iter - 1:\n",
    "                    print(f\"Não convergiu em {self.max_iter} iterações\")\n",
    "    \n",
    "        return historico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5700978e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k               y_k      B   g(x)         grad_g(x)  ||grad_g(x)||   g(y)  \\\n",
      "0  0  [-2.496, -1.407]  2.866  0.171   [-0.058, 0.033]          0.066  0.171   \n",
      "1  1  [-0.906, -0.871]  1.257  0.049   [-0.073, 0.019]          0.075  0.049   \n",
      "2  2  [-0.162, -0.224]  0.276  0.010  [-0.006, -0.041]          0.042  0.010   \n",
      "3  3  [-0.003, -0.001]  0.003  0.000    [-0.0, -0.046]          0.046  0.000   \n",
      "4  4      [-0.0, -0.0]  0.000  0.000     [0.0, -0.047]          0.047  0.000   \n",
      "\n",
      "              x_k  \n",
      "0    [0.05, 0.62]  \n",
      "1  [0.352, 0.662]  \n",
      "2   [0.49, 0.759]  \n",
      "3    [0.499, 0.8]  \n",
      "4      [0.5, 0.8]  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Equação do estado limite g(X)\n",
    "X1,e,P,L = sp.symbols('X1 e P L')\n",
    "vetor_simbolico_x = [X1, P]\n",
    "e = 0.05\n",
    "L = 1\n",
    "g_sym_function = (L / 4) - e - (P * (X1 - ((X1**2) / L)))\n",
    "\n",
    "def g_fun_numerica(x: np.ndarray) -> float:\n",
    "    e = 0.05\n",
    "    L = 1\n",
    "    return (L / 4) - e - (x[1] * (x[0] - ((x[0]**2) / L)))\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite g(X)\n",
    "Y1,e,p,L = sp.symbols('Y1 e p L')\n",
    "vetor_simbolico_y = [Y1, p]\n",
    "def g_y_simbolico_fun (vetor_x_simbolico):\n",
    "    e = 0.05\n",
    "    L = 1\n",
    "    return (L / 4) - e - (vetor_x_simbolico[1] * (vetor_x_simbolico[0] - ((vetor_x_simbolico[0]**2) / L)))\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "X1 = variavel_aleatoria(distribuicao='uniforme', nome='Posicao', simbolo='X1')\n",
    "a_x_1 = 0\n",
    "b_x_1 = 1\n",
    "amplitude_x_1 = b_x_1 - a_x_1\n",
    "X1.conjunto_parametros(a_x_1, amplitude_x_1) \n",
    "\n",
    "X2 = variavel_aleatoria(distribuicao='uniforme', nome='Carga', simbolo='X2')\n",
    "a_x_2 = 0.6\n",
    "b_x_2 = 1\n",
    "amplitude_x_2 = b_x_2 - a_x_2\n",
    "X2.conjunto_parametros(a_x_2, amplitude_x_2) \n",
    "\n",
    "vetor_va = [X1, X2]\n",
    "\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((2, 2)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada = np.array([\n",
    "    [1.0, 0.5],\n",
    "    [0.5, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va)\n",
    "vx_obj.matriz_correlacao_x = Rx_entrada\n",
    "Rz = vx_obj.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start = np.array([0.05, 0.62])\n",
    "ponto_projeto_obj = Ponto_projeto_iHRLF_mod(vx_obj, g_fun_numerica, vetor_simbolico_y, g_y_simbolico_fun, g_sym_function, vetor_simbolico_x, x_start, max_iter=500)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração = ponto_projeto_obj.execution()\n",
    "dados_arredondados = [[np.round(x, 3) for x in linha] for linha in resultado_iteração]\n",
    "\n",
    "# Montagem da tabela\n",
    "tabela = pd.DataFrame(dados_arredondados, columns=['k', 'y_k', 'B', 'g(x)', 'grad_g(x)', '||grad_g(x)||', 'g(y)', 'x_k' ])\n",
    "\n",
    "#Plot\n",
    "# Vetor com os valores de das variáveis\n",
    "coluna_vetor_x = tabela['x_k'] \n",
    "\n",
    "# Separação de X1 e X2\n",
    "X1_coords = coluna_vetor_x.apply(lambda vec: vec[0]) # Pega a 1ª componente (Posição)\n",
    "X2_coords = coluna_vetor_x.apply(lambda vec: vec[1]) # Pega a 2ª componente (Carga P)\n",
    "\n",
    "# Dominio a ser aplicado à g(X)\n",
    "X1_min, X1_max = a_x_1, b_x_1 # Limites da Uniforme X1\n",
    "X2_min, X2_max = a_x_2, b_x_2 # Limites da Uniforme X2 (corrigido!)\n",
    "\n",
    "# Cria uma grade (mesh) de 100x100 pontos para X1 e X2\n",
    "num_points = 100\n",
    "X1_grid = np.linspace(X1_min, X1_max, num_points)\n",
    "X2_grid = np.linspace(X2_min, X2_max, num_points)\n",
    "X_mesh_1, X_mesh_2 = np.meshgrid(X1_grid, X2_grid)\n",
    "\n",
    "# Calculo de g(X)\n",
    "G_values = np.zeros(X_mesh_1.shape)\n",
    "for i in range(num_points):\n",
    "    for j in range(num_points):\n",
    "        x_point = np.array([X_mesh_1[i, j], X_mesh_2[i, j]])\n",
    "        G_values[i, j] = g_fun_numerica(x_point)\n",
    "\n",
    "# Contorno dos valores possíveis\n",
    "plt.plot([X1_min, X1_max, X1_max, X1_min, X1_min], \n",
    "         [X2_min, X2_min, X2_max, X2_max, X2_min], \n",
    "         color='gray', linestyle='-', linewidth=1)\n",
    "\n",
    "# Plot de g(X)\n",
    "plt.contour(X_mesh_1, X_mesh_2, G_values, levels=[0], colors='gray', linestyles='-', linewidths=2, label='g(X)=0')\n",
    "\n",
    "# Trajetória de convergência\n",
    "plt.plot(X1_coords, X2_coords, marker='o',linestyle='', color='tab:blue')\n",
    "plt.scatter(X1_coords.iloc[-1], X2_coords.iloc[-1], color='red', marker='o')\n",
    "\n",
    "# Anotações dos pontos\n",
    "for k, (x1, x2) in enumerate(zip(X1_coords, X2_coords)):\n",
    "    plt.annotate(str(k), (x1, x2), textcoords=\"offset points\", xytext=(5,5), ha='center')\n",
    "\n",
    "# Ajusta os limites do eixo para cobrir o domínio e um pouco mais\n",
    "plt.xlim(X1_min - 0.1*(X1_max-X1_min), X1_max + 0.1*(X1_max-X1_min))\n",
    "plt.ylim(X2_min - 0.1*(X2_max-X2_min), X2_max + 0.1*(X2_max-X2_min))\n",
    "\n",
    "plt.xlabel('Position D')\n",
    "plt.ylabel('Load P')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(tabela)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d81ea3",
   "metadata": {},
   "source": [
    "# Tarefa T9\n",
    "Para a resolução da tarefa 9, vamos utilizar o algoritmo HLRF abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b84333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import sympy as sp\n",
    "from sympy.utilities.lambdify import lambdify\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "class Ponto_projeto_HRLF:\n",
    "    def __init__(self, vx_obj, g_fun_numerica_x, vetor_simbolico_y, g_y_simbolico, g_sym_fun, vetor_simbolico, x_inicial, max_iter=100):\n",
    "\n",
    "        # Inicialização das variáveis\n",
    "        self.vx_obj = vx_obj \n",
    "        self.g_fun_x_num = g_fun_numerica_x\n",
    "        self.vetor_simbolico_y = vetor_simbolico_y\n",
    "        self.g_y_simbolico = g_y_simbolico\n",
    "        self.grad_g_x_fun = self.calcular_gradiente_simbolico_x(g_sym_fun, vetor_simbolico)\n",
    "        self.x_estrela_atual = x_inicial\n",
    "        self.max_iter = max_iter\n",
    "        self.historico = []\n",
    "\n",
    "    # Atualização das matrizes de média e desvio padrão equivalente\n",
    "    def normal_equivalente_no_ponto (self, vetor_x: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "        mu_neq_lista = []\n",
    "        sigma_neq_lista = []\n",
    "\n",
    "        for i, va in enumerate(self.vx_obj.vetor_va_cust):\n",
    "            x_i = vetor_x[i]\n",
    "\n",
    "            cdf_xi = va.CDF(x_i)\n",
    "            pdf_xi = va.PDF(x_i)\n",
    "\n",
    "            z_i = sc.stats.norm.ppf(cdf_xi)\n",
    "            phi_zi = sc.stats.norm.pdf(z_i)\n",
    "\n",
    "            sigma_neq_i = phi_zi / pdf_xi\n",
    "            mu_neq_i = x_i - (z_i * sigma_neq_i)\n",
    "\n",
    "            mu_neq_lista.append(mu_neq_i)\n",
    "            sigma_neq_lista.append(sigma_neq_i)\n",
    "\n",
    "        return np.array(mu_neq_lista), np.diag(sigma_neq_lista)\n",
    "    \n",
    "    # Calculo do gradiente numérico da função g(x) a partir da função simbólica fornecida paara g(x)\n",
    "    def calcular_gradiente_simbolico_x(self, g_sym:sp.Expr, vetor_simbolico: List[sp.Symbol]) -> Callable:\n",
    "        \n",
    "        grad_g_sym = [sp.diff(g_sym, x_i) for x_i in vetor_simbolico]\n",
    "\n",
    "        grad_g_numeric = lambdify(vetor_simbolico, grad_g_sym, 'numpy')\n",
    "        \n",
    "        def grad_g_x_numerico(x_vals: np.ndarray) -> np.ndarray:\n",
    "            return np.array(grad_g_numeric(*x_vals))\n",
    "        \n",
    "        return grad_g_x_numerico\n",
    "     \n",
    "    # Estrutura principal de calculo e iteração em busca do ponto de projeto\n",
    "    def execution (self,):\n",
    "\n",
    "        historico = [] # Vetor que armazena o histórico de iterações\n",
    "\n",
    "        for k in range(self.max_iter):\n",
    "            \n",
    "            # Ponto de projeto x* para a iteração k\n",
    "            x_k = self.x_estrela_atual \n",
    "\n",
    "            # Atualização das matrizes de média e desvio padrão equivalentes para o ponto x_k\n",
    "            # Calculo dos Jacobianos da transformação X -> Z\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            vetor_simbolico_y = self.vetor_simbolico_y\n",
    "            vetor_simbolico_x_calc = (J_xy @ vetor_simbolico_y) + mu_neq\n",
    "            g_y_simbolico = self.g_y_simbolico(vetor_simbolico_x_calc)\n",
    "            g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "            \n",
    "            def calculo_g_y(vetor_y):\n",
    "                return g_y_numerico(*vetor_y)\n",
    "            \n",
    "            # Trandformação do ponto xk -> yk\n",
    "            y_k = J_yx @ (x_k - mu_neq)\n",
    "\n",
    "            # Calculo do índice de confiabilidade para o ponto yk\n",
    "            beta_k = np.linalg.norm(y_k)\n",
    "            \n",
    "            # Avaliação das funções g(x) em x_k e g(y) em y_k\n",
    "            g_x = self.g_fun_x_num(x_k)\n",
    "            g_y = calculo_g_y(y_k)\n",
    "\n",
    "            if k == 0:\n",
    "                g_y_zero = g_y\n",
    "\n",
    "            # Calculo do gradiente de g(x) no espaço de projeto X em x_k\n",
    "            grad_g_x = self.grad_g_x_fun(x_k)\n",
    "\n",
    "            # Calculo do gradiente de g(y) em y_k a partir da transformação X -> Y\n",
    "            grad_g_y = (J_xy.T) @ grad_g_x\n",
    "\n",
    "            # Calculo dos coeficientes de sensibilidade\n",
    "            alpha = grad_g_y / np.linalg.norm(grad_g_y)\n",
    "\n",
    "            historico.append([\n",
    "                k, \n",
    "                y_k, \n",
    "                beta_k, \n",
    "                g_x, \n",
    "                grad_g_y, \n",
    "                np.linalg.norm(grad_g_y),\n",
    "                g_y,\n",
    "                x_k\n",
    "            ])  \n",
    "\n",
    "            # Calculo do ponto de projeto y_k+1\n",
    "            y_k_mais_1 = (((1 / np.linalg.norm(grad_g_y)) ** 2) * (((grad_g_y.T) @ y_k) - g_y)) * grad_g_y # Algoritmo HLRF\n",
    "            #y_k_mais_1 = - alpha * (beta_k + ((g_y) / np.linalg.norm(grad_g_y)))\n",
    "            \n",
    "            # Calculo do ponto x_k+1 a partir da tranformação Y -> X\n",
    "            x_k_mais_1 = (J_xy @ y_k_mais_1) + mu_neq\n",
    "\n",
    "            mu_neq, D_neq = self.normal_equivalente_no_ponto(x_k_mais_1)\n",
    "            D_neq_inv = np.linalg.inv(D_neq)\n",
    "            J_yz = self.vx_obj.decomposicao_cholesky()[0]\n",
    "            J_zy = self.vx_obj.decomposicao_cholesky()[1]\n",
    "\n",
    "            # Atualização dos Jacobianos da transformação X -> Y\n",
    "            J_xy = D_neq @ J_zy\n",
    "            J_yx = J_yz @ D_neq_inv\n",
    "\n",
    "            vetor_simbolico_y = self.vetor_simbolico_y\n",
    "            vetor_simbolico_x_calc = (J_xy @ vetor_simbolico_y) + mu_neq\n",
    "            g_y_simbolico = self.g_y_simbolico(vetor_simbolico_x_calc)\n",
    "            g_y_numerico = lambdify(vetor_simbolico_y, g_y_simbolico, 'numpy')\n",
    "            def calculo_g_y(vetor_y):\n",
    "                return g_y_numerico(*vetor_y)\n",
    "\n",
    "            # Verificação da convergência do ponto y_k+1\n",
    "            ep = 1e-3    \n",
    "            g_x_mais_1 = self.g_fun_x_num(x_k_mais_1)\n",
    "            grad_x_mais_1 = self.grad_g_x_fun(x_k_mais_1)\n",
    "\n",
    "            g_y_mais_1 = calculo_g_y(y_k_mais_1)\n",
    "            grad_y_mais_1 = (J_xy.T) @ grad_x_mais_1\n",
    "\n",
    "            alpha_mais_1 = grad_y_mais_1 / np.linalg.norm(grad_y_mais_1)\n",
    "\n",
    "            verificador = 1 - (abs((grad_y_mais_1.T @ y_k_mais_1) / ((np.linalg.norm(grad_y_mais_1)) * (np.linalg.norm(y_k_mais_1)))))\n",
    "            \n",
    "            if verificador < ep:\n",
    "                if abs(g_y_mais_1) < abs (ep * g_y_zero):\n",
    "\n",
    "                    historico.append([\n",
    "                        k+1, \n",
    "                        y_k_mais_1, \n",
    "                        np.linalg.norm(y_k_mais_1), \n",
    "                        g_x_mais_1, \n",
    "                        grad_y_mais_1, \n",
    "                        np.linalg.norm(grad_y_mais_1),\n",
    "                        g_y_mais_1,\n",
    "                        x_k_mais_1\n",
    "                    ])  \n",
    "\n",
    "                    break\n",
    "                else:\n",
    "                    self.x_estrela_atual = x_k_mais_1 \n",
    "            else:\n",
    "                self.x_estrela_atual = x_k_mais_1\n",
    "\n",
    "                if k == self.max_iter - 1:\n",
    "                    print(f\"Não convergiu em {self.max_iter} iterações\")\n",
    "    \n",
    "        return historico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c077919",
   "metadata": {},
   "source": [
    "Com o objetivo de validar o algoritmo de busca, vamos resolver inicialmente o exemplo 8 do livro, considerando a distribuição normal das variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8050aadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando os limites bi-modais:\n",
      "Temos que o limite inferiror é 0.00024481642446670286\n",
      "Temos que o limite superior é 0.0002448567132134047\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parâmetros gerais\n",
    "r_1 = 4.0 #Raio da barra em metros\n",
    "r_2 = 5.2 #Raio da barra em metros\n",
    "A_1 = np.pi * (r_1 ** 2)\n",
    "A_2 = np.pi * (r_2 ** 2)\n",
    "I_1 = (np.pi * (r_1**4)) / 4\n",
    "I_2 = (np.pi * (r_2**4)) / 4\n",
    "v = 0.3 # Vão da treliça em metros\n",
    "k = 0.5 # Fator correspondente a altura\n",
    "h = k * v\n",
    "L = np.sqrt((v**2) + (h**2))\n",
    "\n",
    "# Equação do estado limite gR1(X)\n",
    "S,H,V = sp.symbols('S H V')\n",
    "vetor_simbolico_gR1 = [S, H, V]\n",
    "g_sym_function_gR1 = ((A_1 * S) / 1000) - ((L / (2 * v)) * (H - (V / k)))\n",
    "\n",
    "def g_fun_numerica_gR1(x: np.ndarray) -> float:\n",
    "    return ((A_1 * x[0]) / 1000) - ((L / (2 * v)) * (x[1] - (x[2] / k)))\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite gR1(X)\n",
    "Y1,Y2,Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun_gR1 (vetor_x_simbolico):\n",
    "    return  ((A_1 * vetor_x_simbolico[0]) / 1000) - ((L / (2 * v)) * (vetor_x_simbolico[1] - (vetor_x_simbolico[2] / k))) \n",
    "\n",
    "# Equação do estado limite gE1(X)\n",
    "E,H,V = sp.symbols('E H V')\n",
    "vetor_simbolico_gE1 = [E, H, V]\n",
    "g_sym_function_gE1 = (((np.pi**2) * E * I_1) / ((L**2) * 1e6)) - ((L / (2 * v)) * (-H + (V / k)))\n",
    "\n",
    "def g_fun_numerica_gE1(x: np.ndarray) -> float:\n",
    "    return (((np.pi**2) * x[0] * I_1) / ((L**2) * 1e6)) - ((L / (2 * v)) * (-x[1] + (x[2] / k)))\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite gE1(X)\n",
    "Y1,Y2,Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun_gE1 (vetor_x_simbolico):\n",
    "    return  (((np.pi**2) * vetor_x_simbolico[0] * I_1) / ((L**2) * 1e6)) - ((L / (2 * v)) * (-vetor_x_simbolico[1] + (vetor_x_simbolico[2] / k)))\n",
    "\n",
    "# Equação do estado limite gE2(X)\n",
    "E,H,V = sp.symbols('E H V')\n",
    "vetor_simbolico_gE2 = [E, H, V]\n",
    "g_sym_function_gE2 = (((np.pi**2) * E * I_2) / ((L**2) * 1e6)) - ((L / (2 * v)) * (H + (V / k)))\n",
    "\n",
    "def g_fun_numerica_gE2(x: np.ndarray) -> float:\n",
    "    return (((np.pi**2) * x[0] * I_2) / ((L**2) * 1e6)) - ((L / (2 * v)) * (x[1] + (x[2] / k)))\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite gE1(X)\n",
    "Y1,Y2,Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun_gE2 (vetor_x_simbolico):\n",
    "    return  (((np.pi**2) * vetor_x_simbolico[0] * I_2) / ((L**2) * 1e6)) - ((L / (2 * v)) * (vetor_x_simbolico[1] + (vetor_x_simbolico[2] / k)))\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "\n",
    "# Tensão de ruptura à tração (MPa)\n",
    "media_S = 24.5643\n",
    "desvio_S = media_S * 0.1\n",
    "S = variavel_aleatoria(distribuicao='normal', nome='Tensao_ruptura', simbolo='S')\n",
    "S.conjunto_parametros(media_S, desvio_S) \n",
    "\n",
    "# Modulo de elasticidade (GPa)\n",
    "media_E = 70.0 \n",
    "desvio_E = media_E * 0.03\n",
    "E = variavel_aleatoria(distribuicao='normal', nome='Modulo_elasticidade', simbolo='E')\n",
    "E.conjunto_parametros(media_E, desvio_E) \n",
    "\n",
    "# Força horizontal (kN)\n",
    "media_H = 2.0 \n",
    "desvio_H = media_H * 0.2\n",
    "H = variavel_aleatoria(distribuicao='normal', nome='Forca_horizontal', simbolo='H')\n",
    "H.conjunto_parametros(media_H, desvio_H) \n",
    "\n",
    "# Força vertical (kN)\n",
    "media_V = 1.0 \n",
    "desvio_V = media_V * 0.2\n",
    "V = variavel_aleatoria(distribuicao='normal', nome='Forca_vertical', simbolo='V')\n",
    "V.conjunto_parametros(media_V, desvio_V) \n",
    "\n",
    "vetor_va_gR1 = [S, H, V]\n",
    "vetor_va_gE1_gE2 = [E, H, V]\n",
    "\n",
    "\n",
    "# Considerando apenas a função gR1\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada_gR1 = np.array([\n",
    "    [1.0, 0, 0],\n",
    "    [0, 1.0, 0],\n",
    "    [0, 0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj_gR1 = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va_gR1)\n",
    "vx_obj_gR1.matriz_correlacao_x = Rx_entrada_gR1\n",
    "Rz = vx_obj_gR1.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj_gR1.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start_gR1 = np.array([media_S, media_H, media_V])\n",
    "ponto_projeto_obj = Ponto_projeto_HRLF(vx_obj_gR1, g_fun_numerica_gR1, vetor_simbolico_gR1, g_y_simbolico_fun_gR1, g_sym_function_gR1, vetor_simbolico_gR1, x_start_gR1, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração_gR1 = ponto_projeto_obj.execution()\n",
    "beta_R1 = resultado_iteração_gR1[1][2]\n",
    "grad_y_R1 = resultado_iteração_gR1[0][4]\n",
    "\n",
    "# Considerando apenas a função gE1\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "\n",
    "Rx_entrada_gE1 = np.array([\n",
    "    [1.0, 0, 0],\n",
    "    [0, 1.0, 0],\n",
    "    [0, 0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj_gE1 = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va_gE1_gE2)\n",
    "vx_obj_gE1.matriz_correlacao_x = Rx_entrada_gE1\n",
    "Rz = vx_obj_gE1.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj_gE1.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start_gE1 = np.array([media_E, media_H, media_V])\n",
    "ponto_projeto_obj = Ponto_projeto_HRLF(vx_obj_gE1, g_fun_numerica_gE1, vetor_simbolico_gE1, g_y_simbolico_fun_gE1, g_sym_function_gE1, vetor_simbolico_gE1, x_start_gE1, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração_gE1 = ponto_projeto_obj.execution()\n",
    "beta_E1 = resultado_iteração_gE1[1][2]\n",
    "grad_y_E1 = resultado_iteração_gE1[0][4]\n",
    "\n",
    "# Considerando apenas a função gE2\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada_gE2 = np.array([\n",
    "    [1.0, 0, 0],\n",
    "    [0, 1.0, 0],\n",
    "    [0, 0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj_gE2 = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va_gE1_gE2)\n",
    "vx_obj_gE2.matriz_correlacao_x = Rx_entrada_gE2\n",
    "Rz = vx_obj_gE2.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj_gE2.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start_gE2 = np.array([media_E, media_H, media_V])\n",
    "ponto_projeto_obj = Ponto_projeto_HRLF(vx_obj_gE2, g_fun_numerica_gE2, vetor_simbolico_gE2, g_y_simbolico_fun_gE2, g_sym_function_gE2, vetor_simbolico_gE2, x_start_gE2, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração_gE2 = ponto_projeto_obj.execution()\n",
    "beta_E2 = resultado_iteração_gE2[1][2]\n",
    "grad_y_E2 = resultado_iteração_gE2[0][4]\n",
    "\n",
    "corr_R1_E1 = (grad_y_R1.T / np.linalg.norm(grad_y_R1)) @ (grad_y_E1 / np.linalg.norm(grad_y_E1))\n",
    "corr_R1_E2 = (grad_y_R1.T / np.linalg.norm(grad_y_R1)) @ (grad_y_E2 / np.linalg.norm(grad_y_E2))\n",
    "corr_E1_E2 = (grad_y_E1.T / np.linalg.norm(grad_y_E1)) @ (grad_y_E2 / np.linalg.norm(grad_y_E2))\n",
    "\n",
    "# Interseção entre E2 e R1\n",
    "# Probabilidade do evento Aij\n",
    "CDF_beta_E2 = st.norm.cdf(-beta_E2)\n",
    "Y_A_ij = (beta_R1 - (corr_R1_E2 * beta_E2)) / (np.sqrt(1 - (corr_R1_E2**2)))\n",
    "P_A_ij = CDF_beta_E2 * st.norm.cdf(-Y_A_ij)\n",
    "\n",
    "# Probabilidade do evento Bij\n",
    "CDF_beta_R1 = st.norm.cdf(-beta_R1)\n",
    "Y_B_ij = (beta_E2 - (corr_R1_E2 * beta_R1)) / (np.sqrt(1 - (corr_R1_E2**2)))\n",
    "P_B_ij = CDF_beta_R1 * st.norm.cdf(-Y_B_ij)\n",
    "\n",
    "if corr_R1_E2 >= 0:\n",
    "    P_E2_inter_R1_inf = P_A_ij + P_B_ij\n",
    "    P_E2_inter_R1_sup = np.maximum(P_A_ij, P_B_ij)\n",
    "else:\n",
    "    P_E2_inter_R1_inf = np.minimum(P_A_ij, P_B_ij)\n",
    "    P_E2_inter_R1_sup = 0\n",
    "\n",
    "# Interseção entre E1 e R1\n",
    "# Probabilidade do evento Aij\n",
    "CDF_beta_E1 = st.norm.cdf(-beta_E1)\n",
    "Y_A_ij = (beta_R1 - (corr_R1_E1 * beta_E1)) / (np.sqrt(1 - (corr_R1_E1**2)))\n",
    "P_A_ij = CDF_beta_E1 * st.norm.cdf(-Y_A_ij)\n",
    "\n",
    "# Probabilidade do evento Bij\n",
    "CDF_beta_R1 = st.norm.cdf(-beta_R1)\n",
    "Y_B_ij = (beta_E1 - (corr_R1_E1 * beta_R1)) / (np.sqrt(1 - (corr_R1_E1**2)))\n",
    "P_B_ij = CDF_beta_R1 * st.norm.cdf(-Y_B_ij)\n",
    "\n",
    "if corr_R1_E1 >= 0:\n",
    "    P_E1_inter_R1_inf = P_A_ij + P_B_ij\n",
    "    P_E1_inter_R1_sup = np.maximum(P_A_ij, P_B_ij)\n",
    "else:\n",
    "    P_E1_inter_R1_inf = np.minimum(P_A_ij, P_B_ij)\n",
    "    P_E1_inter_R1_sup = 0\n",
    "\n",
    "# Interseção entre E1 e E2\n",
    "# Probabilidade do evento Aij\n",
    "CDF_beta_E1 = st.norm.cdf(-beta_E1)\n",
    "Y_A_ij = (beta_E2 - (corr_E1_E2 * beta_E1)) / (np.sqrt(1 - (corr_E1_E2**2)))\n",
    "P_A_ij = CDF_beta_E1 * st.norm.cdf(-Y_A_ij)\n",
    "\n",
    "# Probabilidade do evento Bij\n",
    "CDF_beta_E2 = st.norm.cdf(-beta_E2)\n",
    "Y_B_ij = (beta_E1 - (corr_E1_E2 * beta_R1)) / (np.sqrt(1 - (corr_E1_E2**2)))\n",
    "P_B_ij = CDF_beta_E2 * st.norm.cdf(-Y_B_ij)\n",
    "\n",
    "if corr_E1_E2 >= 0:\n",
    "    P_E1_inter_E2_inf = P_A_ij + P_B_ij\n",
    "    P_E1_inter_E2_sup = np.maximum(P_A_ij, P_B_ij)\n",
    "else:\n",
    "    P_E1_inter_E2_inf = np.minimum(P_A_ij, P_B_ij)\n",
    "    P_E1_inter_E2_sup = 0\n",
    "\n",
    "# Limite inferior da probbilidade de falha do sistema\n",
    "CDF_beta_R1 = st.norm.cdf(-beta_R1)\n",
    "CDF_beta_E2 = st.norm.cdf(-beta_E2)\n",
    "CDF_beta_E1 = st.norm.cdf(-beta_E1)\n",
    "\n",
    "pf_sis_inf = CDF_beta_R1 + CDF_beta_E2 + CDF_beta_E1 - P_E2_inter_R1_inf - P_E1_inter_R1_inf - P_E1_inter_E2_inf\n",
    "\n",
    "# Limite superior da probbilidade de falha do sistema\n",
    "pf_sis_sup = CDF_beta_R1 + CDF_beta_E2 + CDF_beta_E1 - P_E2_inter_R1_sup - (np.maximum(P_E1_inter_R1_sup, P_E1_inter_E2_sup))\n",
    "\n",
    "print(\"Utilizando os limites bi-modais:\")\n",
    "print(f\"Temos que o limite inferiror é {pf_sis_inf}\")\n",
    "print(f\"Temos que o limite superior é {pf_sis_sup}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aad0af9",
   "metadata": {},
   "source": [
    "Uma vez que o o algoritmo conseguiu reproduzir os resultados do exemplo 8, agora vamos resolve-lo considerando distirbuições log-normais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6592689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando os limites bi-modais e distribuições log-normal:\n",
      "Temos que o limite inferiror é 0.00038538496030342\n",
      "Temos que o limite superior é 0.00038541334453312044\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parâmetros gerais\n",
    "r_1 = 4.0 #Raio da barra em metros\n",
    "r_2 = 5.2 #Raio da barra em metros\n",
    "A_1 = np.pi * (r_1 ** 2)\n",
    "A_2 = np.pi * (r_2 ** 2)\n",
    "I_1 = (np.pi * (r_1**4)) / 4\n",
    "I_2 = (np.pi * (r_2**4)) / 4\n",
    "v = 0.3 # Vão da treliça em metros\n",
    "k = 0.5 # Fator correspondente a altura\n",
    "h = k * v\n",
    "L = np.sqrt((v**2) + (h**2))\n",
    "\n",
    "# Equação do estado limite gR1(X)\n",
    "S,H,V = sp.symbols('S H V')\n",
    "vetor_simbolico_gR1 = [S, H, V]\n",
    "g_sym_function_gR1 = ((A_1 * S) / 1000) - ((L / (2 * v)) * (H - (V / k)))\n",
    "\n",
    "def g_fun_numerica_gR1(x: np.ndarray) -> float:\n",
    "    return ((A_1 * x[0]) / 1000) - ((L / (2 * v)) * (x[1] - (x[2] / k)))\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite gR1(X)\n",
    "Y1,Y2,Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun_gR1 (vetor_x_simbolico):\n",
    "    return  ((A_1 * vetor_x_simbolico[0]) / 1000) - ((L / (2 * v)) * (vetor_x_simbolico[1] - (vetor_x_simbolico[2] / k))) \n",
    "\n",
    "# Equação do estado limite gE1(X)\n",
    "E,H,V = sp.symbols('E H V')\n",
    "vetor_simbolico_gE1 = [E, H, V]\n",
    "g_sym_function_gE1 = (((np.pi**2) * E * I_1) / ((L**2) * 1e6)) - ((L / (2 * v)) * (-H + (V / k)))\n",
    "\n",
    "def g_fun_numerica_gE1(x: np.ndarray) -> float:\n",
    "    return (((np.pi**2) * x[0] * I_1) / ((L**2) * 1e6)) - ((L / (2 * v)) * (-x[1] + (x[2] / k)))\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite gE1(X)\n",
    "Y1,Y2,Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun_gE1 (vetor_x_simbolico):\n",
    "    return  (((np.pi**2) * vetor_x_simbolico[0] * I_1) / ((L**2) * 1e6)) - ((L / (2 * v)) * (-vetor_x_simbolico[1] + (vetor_x_simbolico[2] / k)))\n",
    "\n",
    "# Equação do estado limite gE2(X)\n",
    "E,H,V = sp.symbols('E H V')\n",
    "vetor_simbolico_gE2 = [E, H, V]\n",
    "g_sym_function_gE2 = (((np.pi**2) * E * I_2) / ((L**2) * 1e6)) - ((L / (2 * v)) * (H + (V / k)))\n",
    "\n",
    "def g_fun_numerica_gE2(x: np.ndarray) -> float:\n",
    "    return (((np.pi**2) * x[0] * I_2) / ((L**2) * 1e6)) - ((L / (2 * v)) * (x[1] + (x[2] / k)))\n",
    "\n",
    "# Transformação X -> Y da equação de estado-limite gE1(X)\n",
    "Y1,Y2,Y3 = sp.symbols('Y1 Y2 Y3')\n",
    "vetor_simbolico_y = [Y1, Y2, Y3]\n",
    "def g_y_simbolico_fun_gE2 (vetor_x_simbolico):\n",
    "    return  (((np.pi**2) * vetor_x_simbolico[0] * I_2) / ((L**2) * 1e6)) - ((L / (2 * v)) * (vetor_x_simbolico[1] + (vetor_x_simbolico[2] / k)))\n",
    "\n",
    "# Descrição das variáveis aleatórias \n",
    "\n",
    "# Tensão de ruptura à tração (MPa)\n",
    "media_S = 24.5643\n",
    "desvio_S = media_S * 0.1\n",
    "S = variavel_aleatoria(distribuicao='lognormal', nome='Tensao_ruptura', simbolo='S')\n",
    "S.calculo_parametros(media_S, desvio_S) \n",
    "\n",
    "# Modulo de elasticidade (GPa)\n",
    "media_E = 70.0 \n",
    "desvio_E = media_E * 0.03\n",
    "E = variavel_aleatoria(distribuicao='lognormal', nome='Modulo_elasticidade', simbolo='E')\n",
    "E.calculo_parametros(media_E, desvio_E) \n",
    "\n",
    "# Força horizontal (kN)\n",
    "media_H = 2.0 \n",
    "desvio_H = media_H * 0.2\n",
    "H = variavel_aleatoria(distribuicao='lognormal', nome='Forca_horizontal', simbolo='H')\n",
    "H.calculo_parametros(media_H, desvio_H) \n",
    "\n",
    "# Força vertical (kN)\n",
    "media_V = 1.0 \n",
    "desvio_V = media_V * 0.2\n",
    "V = variavel_aleatoria(distribuicao='lognormal', nome='Forca_vertical', simbolo='V')\n",
    "V.calculo_parametros(media_V, desvio_V) \n",
    "\n",
    "vetor_va_gR1 = [S, H, V]\n",
    "vetor_va_gE1_gE2 = [E, H, V]\n",
    "\n",
    "\n",
    "# Considerando apenas a função gR1\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada_gR1 = np.array([\n",
    "    [1.0, 0, 0],\n",
    "    [0, 1.0, 0],\n",
    "    [0, 0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj_gR1 = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va_gR1)\n",
    "vx_obj_gR1.matriz_correlacao_x = Rx_entrada_gR1\n",
    "Rz = vx_obj_gR1.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj_gR1.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start_gR1 = np.array([media_S, media_H, media_V])\n",
    "ponto_projeto_obj = Ponto_projeto_HRLF(vx_obj_gR1, g_fun_numerica_gR1, vetor_simbolico_gR1, g_y_simbolico_fun_gR1, g_sym_function_gR1, vetor_simbolico_gR1, x_start_gR1, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração_gR1 = ponto_projeto_obj.execution()\n",
    "beta_R1 = resultado_iteração_gR1[1][2]\n",
    "grad_y_R1 = resultado_iteração_gR1[0][4]\n",
    "\n",
    "# Considerando apenas a função gE1\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "\n",
    "Rx_entrada_gE1 = np.array([\n",
    "    [1.0, 0, 0],\n",
    "    [0, 1.0, 0],\n",
    "    [0, 0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj_gE1 = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va_gE1_gE2)\n",
    "vx_obj_gE1.matriz_correlacao_x = Rx_entrada_gE1\n",
    "Rz = vx_obj_gE1.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj_gE1.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start_gE1 = np.array([media_E, media_H, media_V])\n",
    "ponto_projeto_obj = Ponto_projeto_HRLF(vx_obj_gE1, g_fun_numerica_gE1, vetor_simbolico_gE1, g_y_simbolico_fun_gE1, g_sym_function_gE1, vetor_simbolico_gE1, x_start_gE1, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração_gE1 = ponto_projeto_obj.execution()\n",
    "beta_E1 = resultado_iteração_gE1[1][2]\n",
    "grad_y_E1 = resultado_iteração_gE1[0][4]\n",
    "\n",
    "# Considerando apenas a função gE2\n",
    "# Montagem das matrizes de observações e correlações\n",
    "matriz_dummy_obs = np.zeros((3, 3)) # Matriz das observações para iniciar o algoritmo\n",
    "\n",
    "Rx_entrada_gE2 = np.array([\n",
    "    [1.0, 0, 0],\n",
    "    [0, 1.0, 0],\n",
    "    [0, 0, 1.0],\n",
    "])\n",
    "\n",
    "# 4. Inicializar VX (T3)\n",
    "vx_obj_gE2 = vetores_variavel_aleatoria(matriz_dummy_obs, vetor_va_gE1_gE2)\n",
    "vx_obj_gE2.matriz_correlacao_x = Rx_entrada_gE2\n",
    "Rz = vx_obj_gE2.matriz_correlacao_nataf() # Garante que Cz é calculado (Cz = Rx = I)\n",
    "J_yz, J_zy = vx_obj_gE2.decomposicao_cholesky()\n",
    "\n",
    "# Ponto inicial (ponto médio)\n",
    "x_start_gE2 = np.array([media_E, media_H, media_V])\n",
    "ponto_projeto_obj = Ponto_projeto_HRLF(vx_obj_gE2, g_fun_numerica_gE2, vetor_simbolico_gE2, g_y_simbolico_fun_gE2, g_sym_function_gE2, vetor_simbolico_gE2, x_start_gE2, max_iter=200)\n",
    "\n",
    "# Resultado da iteração\n",
    "resultado_iteração_gE2 = ponto_projeto_obj.execution()\n",
    "beta_E2 = resultado_iteração_gE2[1][2]\n",
    "grad_y_E2 = resultado_iteração_gE2[0][4]\n",
    "\n",
    "corr_R1_E1 = (grad_y_R1.T / np.linalg.norm(grad_y_R1)) @ (grad_y_E1 / np.linalg.norm(grad_y_E1))\n",
    "corr_R1_E2 = (grad_y_R1.T / np.linalg.norm(grad_y_R1)) @ (grad_y_E2 / np.linalg.norm(grad_y_E2))\n",
    "corr_E1_E2 = (grad_y_E1.T / np.linalg.norm(grad_y_E1)) @ (grad_y_E2 / np.linalg.norm(grad_y_E2))\n",
    "\n",
    "# Interseção entre E2 e R1\n",
    "# Probabilidade do evento Aij\n",
    "CDF_beta_E2 = st.norm.cdf(-beta_E2)\n",
    "Y_A_ij = (beta_R1 - (corr_R1_E2 * beta_E2)) / (np.sqrt(1 - (corr_R1_E2**2)))\n",
    "P_A_ij = CDF_beta_E2 * st.norm.cdf(-Y_A_ij)\n",
    "\n",
    "# Probabilidade do evento Bij\n",
    "CDF_beta_R1 = st.norm.cdf(-beta_R1)\n",
    "Y_B_ij = (beta_E2 - (corr_R1_E2 * beta_R1)) / (np.sqrt(1 - (corr_R1_E2**2)))\n",
    "P_B_ij = CDF_beta_R1 * st.norm.cdf(-Y_B_ij)\n",
    "\n",
    "if corr_R1_E2 >= 0:\n",
    "    P_E2_inter_R1_inf = P_A_ij + P_B_ij\n",
    "    P_E2_inter_R1_sup = np.maximum(P_A_ij, P_B_ij)\n",
    "else:\n",
    "    P_E2_inter_R1_inf = np.minimum(P_A_ij, P_B_ij)\n",
    "    P_E2_inter_R1_sup = 0\n",
    "\n",
    "# Interseção entre E1 e R1\n",
    "# Probabilidade do evento Aij\n",
    "CDF_beta_E1 = st.norm.cdf(-beta_E1)\n",
    "Y_A_ij = (beta_R1 - (corr_R1_E1 * beta_E1)) / (np.sqrt(1 - (corr_R1_E1**2)))\n",
    "P_A_ij = CDF_beta_E1 * st.norm.cdf(-Y_A_ij)\n",
    "\n",
    "# Probabilidade do evento Bij\n",
    "CDF_beta_R1 = st.norm.cdf(-beta_R1)\n",
    "Y_B_ij = (beta_E1 - (corr_R1_E1 * beta_R1)) / (np.sqrt(1 - (corr_R1_E1**2)))\n",
    "P_B_ij = CDF_beta_R1 * st.norm.cdf(-Y_B_ij)\n",
    "\n",
    "if corr_R1_E1 >= 0:\n",
    "    P_E1_inter_R1_inf = P_A_ij + P_B_ij\n",
    "    P_E1_inter_R1_sup = np.maximum(P_A_ij, P_B_ij)\n",
    "else:\n",
    "    P_E1_inter_R1_inf = np.minimum(P_A_ij, P_B_ij)\n",
    "    P_E1_inter_R1_sup = 0\n",
    "\n",
    "# Interseção entre E1 e E2\n",
    "# Probabilidade do evento Aij\n",
    "CDF_beta_E1 = st.norm.cdf(-beta_E1)\n",
    "Y_A_ij = (beta_E2 - (corr_E1_E2 * beta_E1)) / (np.sqrt(1 - (corr_E1_E2**2)))\n",
    "P_A_ij = CDF_beta_E1 * st.norm.cdf(-Y_A_ij)\n",
    "\n",
    "# Probabilidade do evento Bij\n",
    "CDF_beta_E2 = st.norm.cdf(-beta_E2)\n",
    "Y_B_ij = (beta_E1 - (corr_E1_E2 * beta_R1)) / (np.sqrt(1 - (corr_E1_E2**2)))\n",
    "P_B_ij = CDF_beta_E2 * st.norm.cdf(-Y_B_ij)\n",
    "\n",
    "if corr_E1_E2 >= 0:\n",
    "    P_E1_inter_E2_inf = P_A_ij + P_B_ij\n",
    "    P_E1_inter_E2_sup = np.maximum(P_A_ij, P_B_ij)\n",
    "else:\n",
    "    P_E1_inter_E2_inf = np.minimum(P_A_ij, P_B_ij)\n",
    "    P_E1_inter_E2_sup = 0\n",
    "\n",
    "# Limite inferior da probbilidade de falha do sistema\n",
    "CDF_beta_R1 = st.norm.cdf(-beta_R1)\n",
    "CDF_beta_E2 = st.norm.cdf(-beta_E2)\n",
    "CDF_beta_E1 = st.norm.cdf(-beta_E1)\n",
    "\n",
    "pf_sis_inf = CDF_beta_R1 + CDF_beta_E2 + CDF_beta_E1 - P_E2_inter_R1_inf - P_E1_inter_R1_inf - P_E1_inter_E2_inf\n",
    "\n",
    "# Limite superior da probbilidade de falha do sistema\n",
    "pf_sis_sup = CDF_beta_R1 + CDF_beta_E2 + CDF_beta_E1 - P_E2_inter_R1_sup - (np.maximum(P_E1_inter_R1_sup, P_E1_inter_E2_sup))\n",
    "\n",
    "print(\"Utilizando os limites bi-modais e distribuições log-normal:\")\n",
    "print(f\"Temos que o limite inferiror é {pf_sis_inf}\")\n",
    "print(f\"Temos que o limite superior é {pf_sis_sup}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe3774",
   "metadata": {},
   "source": [
    "# Tarefa 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (confiabilidade_env)",
   "language": "python",
   "name": "confiabilidade_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
